{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.convr = nn.Conv1d(in_channels=in_channels, out_channels=64, kernel_size=1)\n",
    "    def forward(self, input):\n",
    "        residual = self.convr(input)\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class TinyFallNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyFallNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=6, out_channels=64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.convblk1 = ConvBlock(64)\n",
    "        self.convblk2 = ConvBlock(64)\n",
    "        self.convblk3 = ConvBlock(64)\n",
    "        self.convblk4 = ConvBlock(64)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool1d(2)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(),\n",
    "                                nn.Linear(in_features=768, out_features=2),\n",
    "                                nn.Softmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblk1(x)\n",
    "        x = self.convblk2(x)\n",
    "        x = self.convblk3(x)\n",
    "        x = self.convblk4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: TinyFallNet(\n",
      "  (conv1): Conv1d(6, 64, kernel_size=(3,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (convblk1): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk2): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk3): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk4): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (pool2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (2): Softmax(dim=None)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.weight | Size: torch.Size([64, 6, 3]) | Values : tensor([[[ 0.2109, -0.1151,  0.0219],\n",
      "         [-0.1926, -0.0720, -0.0188],\n",
      "         [-0.0869, -0.1123, -0.2333],\n",
      "         [-0.0694,  0.1718, -0.1513],\n",
      "         [-0.1700,  0.2094, -0.2275],\n",
      "         [ 0.0433,  0.1784,  0.1082]],\n",
      "\n",
      "        [[ 0.1368,  0.1534,  0.1535],\n",
      "         [ 0.1021,  0.2189,  0.0513],\n",
      "         [-0.2106,  0.0071,  0.2331],\n",
      "         [ 0.0774,  0.1544, -0.2004],\n",
      "         [ 0.1945,  0.0536,  0.0052],\n",
      "         [-0.1968, -0.1882, -0.2181]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.bias | Size: torch.Size([64]) | Values : tensor([0.0939, 0.0139], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0399],\n",
      "         [ 0.0481],\n",
      "         [ 0.0677],\n",
      "         [ 0.1142],\n",
      "         [-0.0457],\n",
      "         [-0.0176],\n",
      "         [ 0.0600],\n",
      "         [-0.0303],\n",
      "         [ 0.0412],\n",
      "         [ 0.0820],\n",
      "         [ 0.0220],\n",
      "         [ 0.0906],\n",
      "         [ 0.1047],\n",
      "         [-0.0989],\n",
      "         [ 0.1123],\n",
      "         [-0.0242],\n",
      "         [-0.0715],\n",
      "         [-0.1136],\n",
      "         [ 0.0036],\n",
      "         [-0.0705],\n",
      "         [ 0.0679],\n",
      "         [-0.0838],\n",
      "         [ 0.1078],\n",
      "         [-0.0282],\n",
      "         [-0.0537],\n",
      "         [ 0.1107],\n",
      "         [ 0.0474],\n",
      "         [-0.0221],\n",
      "         [-0.1249],\n",
      "         [-0.0751],\n",
      "         [-0.0960],\n",
      "         [ 0.1001],\n",
      "         [-0.0766],\n",
      "         [-0.0736],\n",
      "         [ 0.0240],\n",
      "         [ 0.0803],\n",
      "         [-0.0388],\n",
      "         [-0.1220],\n",
      "         [-0.1118],\n",
      "         [ 0.0608],\n",
      "         [ 0.0593],\n",
      "         [-0.1001],\n",
      "         [-0.0973],\n",
      "         [ 0.0974],\n",
      "         [ 0.0232],\n",
      "         [ 0.0771],\n",
      "         [ 0.0922],\n",
      "         [-0.0206],\n",
      "         [-0.0235],\n",
      "         [-0.0730],\n",
      "         [ 0.0390],\n",
      "         [-0.1045],\n",
      "         [ 0.1027],\n",
      "         [-0.0082],\n",
      "         [-0.0686],\n",
      "         [-0.0396],\n",
      "         [ 0.0591],\n",
      "         [-0.1160],\n",
      "         [-0.0005],\n",
      "         [-0.0012],\n",
      "         [ 0.0584],\n",
      "         [ 0.0518],\n",
      "         [-0.0651],\n",
      "         [-0.0505]],\n",
      "\n",
      "        [[-0.0475],\n",
      "         [-0.0041],\n",
      "         [-0.0774],\n",
      "         [ 0.0972],\n",
      "         [ 0.0670],\n",
      "         [-0.1249],\n",
      "         [ 0.0547],\n",
      "         [-0.1048],\n",
      "         [-0.0262],\n",
      "         [-0.0117],\n",
      "         [ 0.1182],\n",
      "         [ 0.0206],\n",
      "         [ 0.0649],\n",
      "         [ 0.1050],\n",
      "         [ 0.0457],\n",
      "         [ 0.0309],\n",
      "         [ 0.1077],\n",
      "         [ 0.0541],\n",
      "         [-0.0616],\n",
      "         [ 0.0971],\n",
      "         [-0.0778],\n",
      "         [-0.0537],\n",
      "         [ 0.0208],\n",
      "         [ 0.0386],\n",
      "         [-0.0530],\n",
      "         [ 0.0367],\n",
      "         [ 0.1046],\n",
      "         [-0.1009],\n",
      "         [-0.1172],\n",
      "         [ 0.0911],\n",
      "         [ 0.1006],\n",
      "         [-0.1245],\n",
      "         [ 0.0680],\n",
      "         [ 0.0415],\n",
      "         [ 0.0110],\n",
      "         [ 0.0178],\n",
      "         [ 0.0580],\n",
      "         [-0.0857],\n",
      "         [ 0.0436],\n",
      "         [-0.0611],\n",
      "         [-0.0587],\n",
      "         [ 0.0381],\n",
      "         [ 0.0697],\n",
      "         [-0.1016],\n",
      "         [-0.1154],\n",
      "         [-0.0803],\n",
      "         [ 0.0998],\n",
      "         [ 0.0683],\n",
      "         [-0.0608],\n",
      "         [-0.0516],\n",
      "         [ 0.0040],\n",
      "         [-0.0915],\n",
      "         [ 0.1098],\n",
      "         [ 0.0790],\n",
      "         [ 0.0702],\n",
      "         [ 0.1135],\n",
      "         [ 0.0276],\n",
      "         [ 0.0154],\n",
      "         [ 0.0204],\n",
      "         [-0.0338],\n",
      "         [ 0.0895],\n",
      "         [ 0.0545],\n",
      "         [-0.0196],\n",
      "         [ 0.0052]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([ 0.0382, -0.0418], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0751,  0.0936,  0.0541],\n",
      "         [ 0.0921, -0.0943,  0.1250],\n",
      "         [ 0.0987, -0.1256,  0.0058],\n",
      "         [ 0.0273, -0.1164,  0.0059],\n",
      "         [-0.0043,  0.0365,  0.0443],\n",
      "         [-0.0624, -0.0227,  0.0288],\n",
      "         [-0.1079,  0.0371,  0.1242],\n",
      "         [-0.1040, -0.1399, -0.0521],\n",
      "         [-0.1027, -0.0870, -0.1427],\n",
      "         [-0.1192, -0.0706, -0.1027],\n",
      "         [-0.0211, -0.0954,  0.0126],\n",
      "         [-0.1162, -0.0096,  0.1360],\n",
      "         [ 0.1299,  0.0401, -0.1121],\n",
      "         [-0.1320,  0.0243,  0.1390],\n",
      "         [ 0.0450, -0.0187, -0.0860],\n",
      "         [-0.1105,  0.0767, -0.0748]],\n",
      "\n",
      "        [[ 0.0355,  0.0570,  0.0728],\n",
      "         [-0.0373,  0.1257, -0.0738],\n",
      "         [ 0.0401, -0.0775, -0.0475],\n",
      "         [ 0.1180, -0.0079, -0.0234],\n",
      "         [ 0.0427, -0.0832, -0.1332],\n",
      "         [ 0.0457, -0.0817,  0.1248],\n",
      "         [-0.1075,  0.1013,  0.1264],\n",
      "         [-0.1130,  0.1209,  0.1178],\n",
      "         [-0.0183, -0.0932,  0.0864],\n",
      "         [-0.0937, -0.1044, -0.0190],\n",
      "         [-0.1362,  0.0762,  0.0354],\n",
      "         [-0.1395,  0.0113, -0.0911],\n",
      "         [ 0.1162, -0.0714,  0.0066],\n",
      "         [ 0.1360,  0.0955, -0.1170],\n",
      "         [-0.0865, -0.0322, -0.1311],\n",
      "         [ 0.0109, -0.0697,  0.0637]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0184, -0.0722], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.2448],\n",
      "         [-0.0674],\n",
      "         [-0.2172],\n",
      "         [ 0.0387],\n",
      "         [-0.0112],\n",
      "         [ 0.0991],\n",
      "         [-0.1724],\n",
      "         [-0.2481],\n",
      "         [ 0.0880],\n",
      "         [-0.0591],\n",
      "         [-0.1821],\n",
      "         [-0.0443],\n",
      "         [-0.1270],\n",
      "         [ 0.1826],\n",
      "         [-0.2382],\n",
      "         [-0.1604]],\n",
      "\n",
      "        [[-0.2272],\n",
      "         [-0.0335],\n",
      "         [ 0.1854],\n",
      "         [-0.1183],\n",
      "         [ 0.0731],\n",
      "         [-0.0997],\n",
      "         [ 0.1963],\n",
      "         [ 0.0782],\n",
      "         [ 0.2331],\n",
      "         [-0.0450],\n",
      "         [ 0.0833],\n",
      "         [ 0.0796],\n",
      "         [ 0.2087],\n",
      "         [ 0.1986],\n",
      "         [-0.1025],\n",
      "         [ 0.0685]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.0382, 0.2221], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0142],\n",
      "         [-0.0967],\n",
      "         [-0.0217],\n",
      "         [ 0.0413],\n",
      "         [ 0.0399],\n",
      "         [ 0.0552],\n",
      "         [-0.0014],\n",
      "         [ 0.0901],\n",
      "         [-0.0584],\n",
      "         [ 0.0517],\n",
      "         [ 0.0841],\n",
      "         [ 0.0556],\n",
      "         [-0.0985],\n",
      "         [ 0.1023],\n",
      "         [-0.0817],\n",
      "         [-0.0891],\n",
      "         [-0.0503],\n",
      "         [ 0.0890],\n",
      "         [ 0.0877],\n",
      "         [-0.0823],\n",
      "         [ 0.0349],\n",
      "         [ 0.0322],\n",
      "         [-0.0631],\n",
      "         [-0.1075],\n",
      "         [ 0.1204],\n",
      "         [ 0.0620],\n",
      "         [ 0.0893],\n",
      "         [ 0.0941],\n",
      "         [-0.1234],\n",
      "         [-0.0369],\n",
      "         [ 0.0440],\n",
      "         [ 0.0259],\n",
      "         [ 0.0569],\n",
      "         [-0.0381],\n",
      "         [ 0.0982],\n",
      "         [ 0.0437],\n",
      "         [-0.1004],\n",
      "         [ 0.0083],\n",
      "         [-0.0735],\n",
      "         [-0.0150],\n",
      "         [ 0.1209],\n",
      "         [-0.0598],\n",
      "         [ 0.0021],\n",
      "         [-0.0295],\n",
      "         [ 0.0496],\n",
      "         [ 0.1004],\n",
      "         [ 0.0666],\n",
      "         [ 0.0355],\n",
      "         [ 0.1109],\n",
      "         [ 0.1231],\n",
      "         [ 0.0583],\n",
      "         [-0.0131],\n",
      "         [ 0.0358],\n",
      "         [-0.0137],\n",
      "         [-0.1227],\n",
      "         [ 0.0681],\n",
      "         [-0.0797],\n",
      "         [-0.0733],\n",
      "         [-0.1109],\n",
      "         [-0.0288],\n",
      "         [-0.0453],\n",
      "         [-0.0389],\n",
      "         [ 0.0726],\n",
      "         [ 0.1154]],\n",
      "\n",
      "        [[ 0.0164],\n",
      "         [ 0.0506],\n",
      "         [ 0.0358],\n",
      "         [-0.0968],\n",
      "         [-0.0880],\n",
      "         [ 0.0983],\n",
      "         [-0.0878],\n",
      "         [-0.0196],\n",
      "         [-0.1145],\n",
      "         [-0.0117],\n",
      "         [ 0.0514],\n",
      "         [ 0.0598],\n",
      "         [ 0.1074],\n",
      "         [ 0.0094],\n",
      "         [-0.0106],\n",
      "         [-0.0564],\n",
      "         [-0.0458],\n",
      "         [ 0.1001],\n",
      "         [-0.1121],\n",
      "         [-0.0116],\n",
      "         [ 0.0016],\n",
      "         [-0.0357],\n",
      "         [ 0.0471],\n",
      "         [ 0.0351],\n",
      "         [ 0.0624],\n",
      "         [-0.1187],\n",
      "         [-0.0568],\n",
      "         [-0.0738],\n",
      "         [ 0.0614],\n",
      "         [-0.1008],\n",
      "         [ 0.0735],\n",
      "         [ 0.0844],\n",
      "         [-0.0681],\n",
      "         [ 0.0933],\n",
      "         [ 0.0922],\n",
      "         [ 0.0728],\n",
      "         [ 0.0383],\n",
      "         [ 0.0223],\n",
      "         [-0.1196],\n",
      "         [ 0.1138],\n",
      "         [ 0.0293],\n",
      "         [-0.0464],\n",
      "         [ 0.1184],\n",
      "         [-0.0445],\n",
      "         [-0.0393],\n",
      "         [ 0.1049],\n",
      "         [ 0.0789],\n",
      "         [-0.0146],\n",
      "         [ 0.0947],\n",
      "         [ 0.1218],\n",
      "         [ 0.0380],\n",
      "         [-0.0591],\n",
      "         [ 0.0045],\n",
      "         [ 0.0194],\n",
      "         [ 0.0270],\n",
      "         [ 0.1114],\n",
      "         [ 0.1241],\n",
      "         [ 0.0679],\n",
      "         [-0.0304],\n",
      "         [ 0.0811],\n",
      "         [ 0.1010],\n",
      "         [ 0.1239],\n",
      "         [ 0.0412],\n",
      "         [ 0.0113]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.bias | Size: torch.Size([64]) | Values : tensor([ 0.0425, -0.0299], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-9.6999e-02],\n",
      "         [-7.4258e-02],\n",
      "         [ 1.0141e-01],\n",
      "         [ 8.6052e-02],\n",
      "         [-5.9051e-02],\n",
      "         [ 1.1408e-02],\n",
      "         [-7.0941e-02],\n",
      "         [-1.0975e-01],\n",
      "         [ 5.9413e-02],\n",
      "         [-5.4688e-02],\n",
      "         [ 1.2426e-02],\n",
      "         [-1.1976e-01],\n",
      "         [ 2.3756e-02],\n",
      "         [-7.1404e-02],\n",
      "         [ 6.1841e-03],\n",
      "         [ 1.9498e-02],\n",
      "         [ 3.6252e-02],\n",
      "         [-1.6766e-02],\n",
      "         [-8.3387e-02],\n",
      "         [-1.2423e-01],\n",
      "         [ 5.1250e-02],\n",
      "         [-5.1251e-02],\n",
      "         [-4.0439e-02],\n",
      "         [ 1.8085e-02],\n",
      "         [ 5.1484e-02],\n",
      "         [ 3.9006e-02],\n",
      "         [ 4.4290e-02],\n",
      "         [-6.8467e-02],\n",
      "         [ 8.4655e-02],\n",
      "         [ 1.1861e-02],\n",
      "         [-1.0053e-02],\n",
      "         [ 8.0878e-02],\n",
      "         [ 7.7547e-02],\n",
      "         [-6.0232e-04],\n",
      "         [ 7.4715e-02],\n",
      "         [-1.0482e-01],\n",
      "         [-9.3915e-02],\n",
      "         [ 8.5488e-05],\n",
      "         [ 1.2060e-01],\n",
      "         [-8.9541e-02],\n",
      "         [-3.2404e-02],\n",
      "         [-8.7111e-03],\n",
      "         [ 8.1028e-02],\n",
      "         [ 1.8572e-02],\n",
      "         [-7.2268e-02],\n",
      "         [-1.1643e-01],\n",
      "         [-1.2061e-01],\n",
      "         [-2.6903e-02],\n",
      "         [-5.4518e-02],\n",
      "         [-2.2885e-02],\n",
      "         [ 6.0954e-02],\n",
      "         [-9.9894e-02],\n",
      "         [-5.2450e-02],\n",
      "         [ 1.4089e-02],\n",
      "         [ 8.1012e-02],\n",
      "         [ 9.6020e-02],\n",
      "         [-9.1468e-02],\n",
      "         [-3.8154e-02],\n",
      "         [ 8.7159e-02],\n",
      "         [ 4.0631e-03],\n",
      "         [-6.0407e-02],\n",
      "         [-2.9157e-02],\n",
      "         [-1.0618e-01],\n",
      "         [ 8.3707e-02]],\n",
      "\n",
      "        [[-2.6292e-02],\n",
      "         [-7.7598e-02],\n",
      "         [ 2.0663e-02],\n",
      "         [-1.2013e-01],\n",
      "         [ 5.1566e-02],\n",
      "         [ 1.0152e-01],\n",
      "         [-8.1199e-02],\n",
      "         [ 6.8645e-02],\n",
      "         [ 7.2775e-02],\n",
      "         [-7.3021e-02],\n",
      "         [-1.2772e-03],\n",
      "         [-2.3633e-02],\n",
      "         [ 5.4366e-03],\n",
      "         [-9.6412e-02],\n",
      "         [ 4.4673e-02],\n",
      "         [ 9.7919e-02],\n",
      "         [-1.9864e-02],\n",
      "         [-3.4009e-02],\n",
      "         [ 1.0347e-01],\n",
      "         [-2.9886e-03],\n",
      "         [ 1.1968e-01],\n",
      "         [-1.1709e-01],\n",
      "         [ 5.5448e-02],\n",
      "         [ 6.9089e-02],\n",
      "         [ 8.5805e-02],\n",
      "         [-9.6304e-02],\n",
      "         [ 6.2281e-02],\n",
      "         [-4.2635e-02],\n",
      "         [ 4.9684e-02],\n",
      "         [ 1.0004e-01],\n",
      "         [-3.6443e-02],\n",
      "         [-1.4269e-02],\n",
      "         [-8.1928e-02],\n",
      "         [-5.4566e-02],\n",
      "         [-6.7471e-02],\n",
      "         [-3.1005e-02],\n",
      "         [ 1.1030e-01],\n",
      "         [ 6.2485e-02],\n",
      "         [-7.4685e-02],\n",
      "         [ 1.1778e-01],\n",
      "         [-8.0043e-02],\n",
      "         [ 1.1929e-01],\n",
      "         [-7.4403e-02],\n",
      "         [ 1.5195e-02],\n",
      "         [ 7.1793e-02],\n",
      "         [-6.9518e-02],\n",
      "         [-5.7315e-02],\n",
      "         [-2.4785e-02],\n",
      "         [ 7.2139e-02],\n",
      "         [-1.8621e-02],\n",
      "         [-2.6065e-03],\n",
      "         [ 1.0833e-01],\n",
      "         [-4.7141e-02],\n",
      "         [-2.7839e-02],\n",
      "         [ 1.0749e-01],\n",
      "         [-8.8083e-02],\n",
      "         [-1.6015e-02],\n",
      "         [-2.6353e-02],\n",
      "         [-1.1566e-01],\n",
      "         [ 8.2694e-02],\n",
      "         [-9.8726e-02],\n",
      "         [-5.3185e-02],\n",
      "         [-5.0792e-02],\n",
      "         [ 3.4855e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0410, -0.1047], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.1324,  0.1155,  0.0801],\n",
      "         [ 0.0958,  0.0135, -0.0657],\n",
      "         [ 0.0160, -0.1203, -0.0245],\n",
      "         [ 0.1415, -0.1424,  0.1401],\n",
      "         [-0.0667,  0.0035, -0.1208],\n",
      "         [ 0.0113,  0.0617,  0.0927],\n",
      "         [-0.0393,  0.0713,  0.1045],\n",
      "         [ 0.1346,  0.0519,  0.0113],\n",
      "         [ 0.0743,  0.0848, -0.0628],\n",
      "         [ 0.1205, -0.0037,  0.0236],\n",
      "         [ 0.0911,  0.0188, -0.1360],\n",
      "         [ 0.1178,  0.1043, -0.1157],\n",
      "         [ 0.0588,  0.1165, -0.0660],\n",
      "         [ 0.0131,  0.0471, -0.0606],\n",
      "         [-0.1174,  0.1314,  0.1348],\n",
      "         [ 0.1153,  0.0538, -0.0935]],\n",
      "\n",
      "        [[ 0.0566,  0.0157,  0.1350],\n",
      "         [-0.1381, -0.0055, -0.0526],\n",
      "         [-0.0720,  0.1116,  0.0464],\n",
      "         [ 0.0085,  0.1364, -0.0849],\n",
      "         [-0.1143, -0.0050, -0.0892],\n",
      "         [ 0.0139,  0.0175, -0.0440],\n",
      "         [-0.1159,  0.0796, -0.0886],\n",
      "         [-0.0576,  0.1014,  0.0824],\n",
      "         [ 0.1001,  0.0979,  0.1379],\n",
      "         [ 0.0983,  0.0331, -0.0869],\n",
      "         [-0.1186, -0.0504,  0.1021],\n",
      "         [-0.1074,  0.1334,  0.0299],\n",
      "         [-0.1087,  0.0878, -0.1067],\n",
      "         [-0.1172, -0.1411,  0.0596],\n",
      "         [-0.0628,  0.0247, -0.1037],\n",
      "         [-0.0587,  0.0046, -0.0760]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.1342, -0.0890], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.0160],\n",
      "         [ 0.1810],\n",
      "         [ 0.1125],\n",
      "         [ 0.0606],\n",
      "         [ 0.2058],\n",
      "         [-0.0017],\n",
      "         [-0.2125],\n",
      "         [ 0.0258],\n",
      "         [ 0.1776],\n",
      "         [ 0.0336],\n",
      "         [-0.1881],\n",
      "         [-0.0353],\n",
      "         [-0.0563],\n",
      "         [ 0.1748],\n",
      "         [-0.1735],\n",
      "         [-0.2410]],\n",
      "\n",
      "        [[-0.0866],\n",
      "         [ 0.1258],\n",
      "         [ 0.0926],\n",
      "         [-0.1852],\n",
      "         [ 0.0552],\n",
      "         [ 0.0025],\n",
      "         [-0.1763],\n",
      "         [ 0.2180],\n",
      "         [-0.1738],\n",
      "         [ 0.1765],\n",
      "         [ 0.2038],\n",
      "         [-0.0500],\n",
      "         [-0.2041],\n",
      "         [-0.0030],\n",
      "         [-0.1568],\n",
      "         [ 0.1556]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.2105, 0.0127], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.1162],\n",
      "         [ 0.1016],\n",
      "         [ 0.0032],\n",
      "         [-0.0027],\n",
      "         [ 0.0472],\n",
      "         [-0.0606],\n",
      "         [-0.0127],\n",
      "         [ 0.0292],\n",
      "         [-0.0849],\n",
      "         [-0.0819],\n",
      "         [ 0.0171],\n",
      "         [-0.1223],\n",
      "         [ 0.1145],\n",
      "         [-0.1200],\n",
      "         [-0.1014],\n",
      "         [ 0.1145],\n",
      "         [-0.0681],\n",
      "         [ 0.0145],\n",
      "         [ 0.0742],\n",
      "         [-0.0086],\n",
      "         [-0.1117],\n",
      "         [-0.0305],\n",
      "         [ 0.0510],\n",
      "         [ 0.0304],\n",
      "         [-0.0221],\n",
      "         [-0.0683],\n",
      "         [ 0.0559],\n",
      "         [-0.0643],\n",
      "         [ 0.0992],\n",
      "         [ 0.0977],\n",
      "         [-0.0824],\n",
      "         [-0.0504],\n",
      "         [ 0.0691],\n",
      "         [-0.1026],\n",
      "         [-0.0653],\n",
      "         [ 0.0489],\n",
      "         [ 0.1203],\n",
      "         [ 0.0284],\n",
      "         [ 0.0953],\n",
      "         [-0.1002],\n",
      "         [-0.1040],\n",
      "         [ 0.1065],\n",
      "         [ 0.0975],\n",
      "         [ 0.0583],\n",
      "         [ 0.1204],\n",
      "         [ 0.1043],\n",
      "         [ 0.0388],\n",
      "         [-0.0248],\n",
      "         [-0.0387],\n",
      "         [-0.0955],\n",
      "         [ 0.0649],\n",
      "         [-0.0353],\n",
      "         [ 0.0726],\n",
      "         [-0.1094],\n",
      "         [-0.0250],\n",
      "         [-0.0639],\n",
      "         [-0.0983],\n",
      "         [ 0.0381],\n",
      "         [-0.0351],\n",
      "         [ 0.0338],\n",
      "         [-0.0019],\n",
      "         [ 0.1058],\n",
      "         [-0.0416],\n",
      "         [-0.0039]],\n",
      "\n",
      "        [[-0.0899],\n",
      "         [-0.0802],\n",
      "         [ 0.0947],\n",
      "         [-0.0491],\n",
      "         [-0.1170],\n",
      "         [ 0.1053],\n",
      "         [ 0.0717],\n",
      "         [ 0.0654],\n",
      "         [ 0.0310],\n",
      "         [ 0.0275],\n",
      "         [-0.1086],\n",
      "         [ 0.0005],\n",
      "         [-0.0689],\n",
      "         [ 0.1030],\n",
      "         [-0.0471],\n",
      "         [ 0.0153],\n",
      "         [ 0.1083],\n",
      "         [-0.0725],\n",
      "         [-0.0829],\n",
      "         [ 0.0840],\n",
      "         [ 0.0358],\n",
      "         [ 0.0512],\n",
      "         [ 0.0500],\n",
      "         [-0.0087],\n",
      "         [ 0.0886],\n",
      "         [-0.0978],\n",
      "         [-0.0779],\n",
      "         [ 0.0165],\n",
      "         [-0.0334],\n",
      "         [-0.0010],\n",
      "         [ 0.0631],\n",
      "         [-0.0633],\n",
      "         [ 0.0294],\n",
      "         [-0.0862],\n",
      "         [-0.0920],\n",
      "         [-0.0105],\n",
      "         [ 0.0937],\n",
      "         [ 0.0583],\n",
      "         [-0.0189],\n",
      "         [-0.0788],\n",
      "         [-0.1016],\n",
      "         [-0.0286],\n",
      "         [ 0.1012],\n",
      "         [ 0.0469],\n",
      "         [ 0.1067],\n",
      "         [-0.0534],\n",
      "         [-0.0181],\n",
      "         [ 0.0273],\n",
      "         [ 0.0624],\n",
      "         [ 0.1113],\n",
      "         [ 0.0331],\n",
      "         [-0.0411],\n",
      "         [-0.0791],\n",
      "         [-0.0679],\n",
      "         [-0.0239],\n",
      "         [-0.0486],\n",
      "         [-0.1159],\n",
      "         [ 0.0071],\n",
      "         [-0.1149],\n",
      "         [-0.1132],\n",
      "         [-0.0429],\n",
      "         [-0.0150],\n",
      "         [ 0.0715],\n",
      "         [ 0.0190]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.bias | Size: torch.Size([64]) | Values : tensor([ 0.0478, -0.0431], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0481],\n",
      "         [-0.0014],\n",
      "         [-0.0372],\n",
      "         [-0.0882],\n",
      "         [-0.0815],\n",
      "         [ 0.0854],\n",
      "         [-0.1081],\n",
      "         [-0.0637],\n",
      "         [-0.0620],\n",
      "         [ 0.0623],\n",
      "         [ 0.0334],\n",
      "         [-0.1003],\n",
      "         [ 0.1177],\n",
      "         [-0.0875],\n",
      "         [ 0.0646],\n",
      "         [-0.0747],\n",
      "         [ 0.0976],\n",
      "         [-0.0888],\n",
      "         [ 0.1129],\n",
      "         [ 0.0002],\n",
      "         [-0.1209],\n",
      "         [ 0.0622],\n",
      "         [-0.0612],\n",
      "         [-0.0647],\n",
      "         [ 0.0129],\n",
      "         [-0.0838],\n",
      "         [-0.0081],\n",
      "         [ 0.0542],\n",
      "         [ 0.0823],\n",
      "         [ 0.0542],\n",
      "         [-0.0009],\n",
      "         [ 0.1231],\n",
      "         [-0.1172],\n",
      "         [-0.1166],\n",
      "         [ 0.0978],\n",
      "         [-0.1021],\n",
      "         [-0.0267],\n",
      "         [-0.0126],\n",
      "         [ 0.0455],\n",
      "         [ 0.0810],\n",
      "         [ 0.0938],\n",
      "         [ 0.0967],\n",
      "         [ 0.0278],\n",
      "         [-0.0178],\n",
      "         [-0.0486],\n",
      "         [-0.0604],\n",
      "         [-0.0754],\n",
      "         [ 0.0327],\n",
      "         [-0.0720],\n",
      "         [-0.1130],\n",
      "         [ 0.0011],\n",
      "         [-0.0956],\n",
      "         [ 0.1182],\n",
      "         [ 0.1066],\n",
      "         [ 0.1082],\n",
      "         [ 0.0170],\n",
      "         [ 0.0584],\n",
      "         [-0.1069],\n",
      "         [ 0.0665],\n",
      "         [ 0.0104],\n",
      "         [ 0.0600],\n",
      "         [ 0.1082],\n",
      "         [ 0.0424],\n",
      "         [-0.0883]],\n",
      "\n",
      "        [[ 0.0080],\n",
      "         [-0.0517],\n",
      "         [ 0.1075],\n",
      "         [ 0.0741],\n",
      "         [ 0.0230],\n",
      "         [-0.0610],\n",
      "         [ 0.0505],\n",
      "         [ 0.0452],\n",
      "         [ 0.0621],\n",
      "         [ 0.0319],\n",
      "         [ 0.0869],\n",
      "         [ 0.1008],\n",
      "         [-0.0490],\n",
      "         [-0.1115],\n",
      "         [-0.1148],\n",
      "         [ 0.1058],\n",
      "         [ 0.0069],\n",
      "         [ 0.0342],\n",
      "         [-0.0945],\n",
      "         [ 0.1097],\n",
      "         [ 0.0177],\n",
      "         [ 0.1126],\n",
      "         [-0.0197],\n",
      "         [ 0.0400],\n",
      "         [-0.0871],\n",
      "         [ 0.0511],\n",
      "         [ 0.0906],\n",
      "         [-0.0091],\n",
      "         [-0.1049],\n",
      "         [ 0.1203],\n",
      "         [-0.0466],\n",
      "         [ 0.0578],\n",
      "         [ 0.0461],\n",
      "         [ 0.0698],\n",
      "         [-0.1033],\n",
      "         [ 0.1245],\n",
      "         [ 0.0229],\n",
      "         [-0.0054],\n",
      "         [ 0.0940],\n",
      "         [ 0.0716],\n",
      "         [ 0.1133],\n",
      "         [-0.1228],\n",
      "         [-0.1129],\n",
      "         [ 0.1135],\n",
      "         [-0.0444],\n",
      "         [ 0.0278],\n",
      "         [-0.0076],\n",
      "         [ 0.0973],\n",
      "         [-0.0031],\n",
      "         [-0.0445],\n",
      "         [-0.1150],\n",
      "         [ 0.0120],\n",
      "         [-0.0337],\n",
      "         [ 0.0727],\n",
      "         [ 0.1089],\n",
      "         [-0.0533],\n",
      "         [ 0.0274],\n",
      "         [-0.0595],\n",
      "         [-0.0297],\n",
      "         [-0.0363],\n",
      "         [-0.0299],\n",
      "         [-0.1116],\n",
      "         [-0.0456],\n",
      "         [-0.0747]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0855,  0.1099], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0768,  0.1385,  0.1205],\n",
      "         [ 0.0811,  0.0228,  0.0227],\n",
      "         [-0.0828, -0.1089,  0.0530],\n",
      "         [ 0.0394, -0.0375,  0.0317],\n",
      "         [-0.0091, -0.0022,  0.1429],\n",
      "         [ 0.0118,  0.0007, -0.1159],\n",
      "         [ 0.0139,  0.0352, -0.0176],\n",
      "         [ 0.1280, -0.1167,  0.0883],\n",
      "         [-0.1210,  0.0470, -0.0729],\n",
      "         [-0.1364,  0.1137, -0.0437],\n",
      "         [ 0.0039,  0.0202, -0.0112],\n",
      "         [ 0.1353, -0.0710, -0.0650],\n",
      "         [-0.0877, -0.0336,  0.0962],\n",
      "         [-0.0774, -0.0860, -0.1385],\n",
      "         [ 0.0477, -0.1262, -0.1206],\n",
      "         [-0.1146,  0.0508, -0.1044]],\n",
      "\n",
      "        [[ 0.0220,  0.1049,  0.0877],\n",
      "         [ 0.1401, -0.0337,  0.1118],\n",
      "         [-0.0886,  0.0469, -0.0135],\n",
      "         [-0.0946,  0.0213,  0.0428],\n",
      "         [-0.1184,  0.1389,  0.0449],\n",
      "         [ 0.1282,  0.0500,  0.0047],\n",
      "         [ 0.0572, -0.1161, -0.0028],\n",
      "         [-0.0612,  0.1247, -0.1133],\n",
      "         [ 0.0297,  0.0550,  0.1256],\n",
      "         [-0.1137,  0.0856,  0.0801],\n",
      "         [-0.1289,  0.0791, -0.0115],\n",
      "         [-0.0655, -0.0845, -0.0349],\n",
      "         [ 0.1157,  0.1380, -0.0544],\n",
      "         [-0.0456,  0.0462, -0.0076],\n",
      "         [-0.1291, -0.0743,  0.1004],\n",
      "         [-0.0539,  0.1373, -0.0965]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0239,  0.0886], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.2483],\n",
      "         [-0.1157],\n",
      "         [ 0.1679],\n",
      "         [ 0.1587],\n",
      "         [-0.1948],\n",
      "         [-0.1758],\n",
      "         [-0.1785],\n",
      "         [-0.0525],\n",
      "         [ 0.2284],\n",
      "         [-0.2038],\n",
      "         [-0.2023],\n",
      "         [-0.1443],\n",
      "         [-0.2021],\n",
      "         [-0.2460],\n",
      "         [-0.2011],\n",
      "         [ 0.0895]],\n",
      "\n",
      "        [[ 0.0226],\n",
      "         [-0.2178],\n",
      "         [ 0.0837],\n",
      "         [ 0.0975],\n",
      "         [ 0.1993],\n",
      "         [ 0.1052],\n",
      "         [ 0.0570],\n",
      "         [ 0.0399],\n",
      "         [ 0.0586],\n",
      "         [ 0.1945],\n",
      "         [ 0.1485],\n",
      "         [-0.1227],\n",
      "         [ 0.1308],\n",
      "         [ 0.2261],\n",
      "         [ 0.2054],\n",
      "         [ 0.1909]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([ 0.0235, -0.0879], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0532],\n",
      "         [ 0.0546],\n",
      "         [ 0.1153],\n",
      "         [-0.0383],\n",
      "         [ 0.0859],\n",
      "         [ 0.1084],\n",
      "         [ 0.0486],\n",
      "         [-0.1036],\n",
      "         [ 0.0767],\n",
      "         [ 0.0701],\n",
      "         [ 0.0316],\n",
      "         [-0.0230],\n",
      "         [-0.0370],\n",
      "         [-0.0747],\n",
      "         [ 0.0621],\n",
      "         [-0.0267],\n",
      "         [-0.0364],\n",
      "         [ 0.1224],\n",
      "         [ 0.0090],\n",
      "         [-0.0131],\n",
      "         [ 0.1123],\n",
      "         [ 0.0798],\n",
      "         [ 0.0806],\n",
      "         [ 0.0743],\n",
      "         [-0.0266],\n",
      "         [ 0.1054],\n",
      "         [-0.0096],\n",
      "         [ 0.0511],\n",
      "         [ 0.1105],\n",
      "         [-0.0086],\n",
      "         [ 0.0871],\n",
      "         [ 0.0141],\n",
      "         [-0.0795],\n",
      "         [-0.0210],\n",
      "         [-0.0411],\n",
      "         [-0.1222],\n",
      "         [-0.1221],\n",
      "         [-0.0844],\n",
      "         [-0.0313],\n",
      "         [-0.0338],\n",
      "         [ 0.0040],\n",
      "         [ 0.0060],\n",
      "         [-0.0775],\n",
      "         [ 0.0946],\n",
      "         [ 0.0355],\n",
      "         [-0.0942],\n",
      "         [ 0.0593],\n",
      "         [ 0.1188],\n",
      "         [ 0.0881],\n",
      "         [ 0.0953],\n",
      "         [-0.1148],\n",
      "         [ 0.0206],\n",
      "         [-0.0476],\n",
      "         [-0.1110],\n",
      "         [ 0.0330],\n",
      "         [ 0.0792],\n",
      "         [-0.1056],\n",
      "         [-0.1140],\n",
      "         [-0.0877],\n",
      "         [-0.0220],\n",
      "         [ 0.0364],\n",
      "         [-0.0254],\n",
      "         [ 0.0682],\n",
      "         [ 0.0205]],\n",
      "\n",
      "        [[ 0.0555],\n",
      "         [-0.0338],\n",
      "         [-0.0068],\n",
      "         [ 0.0914],\n",
      "         [-0.0414],\n",
      "         [ 0.0326],\n",
      "         [-0.0402],\n",
      "         [ 0.1234],\n",
      "         [-0.0255],\n",
      "         [ 0.1037],\n",
      "         [ 0.1235],\n",
      "         [ 0.0834],\n",
      "         [ 0.0832],\n",
      "         [ 0.1057],\n",
      "         [-0.1128],\n",
      "         [ 0.0751],\n",
      "         [-0.0209],\n",
      "         [-0.0792],\n",
      "         [ 0.0824],\n",
      "         [ 0.1098],\n",
      "         [-0.0803],\n",
      "         [-0.0124],\n",
      "         [ 0.0339],\n",
      "         [ 0.0139],\n",
      "         [-0.1091],\n",
      "         [ 0.0431],\n",
      "         [ 0.0645],\n",
      "         [ 0.1154],\n",
      "         [-0.0277],\n",
      "         [ 0.1126],\n",
      "         [-0.0861],\n",
      "         [ 0.1248],\n",
      "         [-0.0090],\n",
      "         [ 0.1133],\n",
      "         [ 0.0494],\n",
      "         [ 0.0982],\n",
      "         [ 0.1184],\n",
      "         [-0.1198],\n",
      "         [-0.0268],\n",
      "         [ 0.0705],\n",
      "         [ 0.1128],\n",
      "         [-0.1036],\n",
      "         [-0.1193],\n",
      "         [ 0.0901],\n",
      "         [ 0.0477],\n",
      "         [ 0.0510],\n",
      "         [-0.0165],\n",
      "         [ 0.0695],\n",
      "         [ 0.1136],\n",
      "         [-0.0737],\n",
      "         [ 0.0299],\n",
      "         [-0.0234],\n",
      "         [-0.0104],\n",
      "         [-0.0942],\n",
      "         [-0.1120],\n",
      "         [ 0.0162],\n",
      "         [ 0.0944],\n",
      "         [ 0.1243],\n",
      "         [ 0.1142],\n",
      "         [ 0.0803],\n",
      "         [-0.0621],\n",
      "         [-0.1181],\n",
      "         [ 0.1004],\n",
      "         [-0.1120]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.bias | Size: torch.Size([64]) | Values : tensor([ 0.0587, -0.0050], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0658],\n",
      "         [-0.1172],\n",
      "         [-0.0516],\n",
      "         [-0.0594],\n",
      "         [-0.0105],\n",
      "         [ 0.0578],\n",
      "         [ 0.1129],\n",
      "         [-0.1034],\n",
      "         [ 0.0075],\n",
      "         [-0.1098],\n",
      "         [ 0.1094],\n",
      "         [-0.0190],\n",
      "         [-0.0090],\n",
      "         [ 0.0097],\n",
      "         [ 0.0912],\n",
      "         [ 0.0367],\n",
      "         [-0.0840],\n",
      "         [-0.0937],\n",
      "         [-0.0055],\n",
      "         [ 0.0441],\n",
      "         [ 0.0043],\n",
      "         [ 0.0493],\n",
      "         [ 0.0037],\n",
      "         [-0.0769],\n",
      "         [ 0.0028],\n",
      "         [-0.0581],\n",
      "         [ 0.0283],\n",
      "         [ 0.0337],\n",
      "         [-0.0624],\n",
      "         [ 0.0431],\n",
      "         [-0.0872],\n",
      "         [ 0.0890],\n",
      "         [-0.0521],\n",
      "         [ 0.0071],\n",
      "         [ 0.0985],\n",
      "         [ 0.0859],\n",
      "         [-0.0410],\n",
      "         [ 0.0625],\n",
      "         [-0.0064],\n",
      "         [ 0.0817],\n",
      "         [-0.0874],\n",
      "         [ 0.1022],\n",
      "         [ 0.0915],\n",
      "         [-0.0890],\n",
      "         [ 0.1198],\n",
      "         [-0.0634],\n",
      "         [-0.0287],\n",
      "         [-0.1223],\n",
      "         [ 0.0437],\n",
      "         [-0.0642],\n",
      "         [ 0.1236],\n",
      "         [-0.0980],\n",
      "         [ 0.0646],\n",
      "         [-0.0832],\n",
      "         [ 0.0822],\n",
      "         [-0.0662],\n",
      "         [-0.1139],\n",
      "         [ 0.0103],\n",
      "         [-0.1071],\n",
      "         [ 0.0970],\n",
      "         [ 0.1246],\n",
      "         [-0.1169],\n",
      "         [-0.0399],\n",
      "         [-0.0647]],\n",
      "\n",
      "        [[ 0.1097],\n",
      "         [ 0.0169],\n",
      "         [ 0.0231],\n",
      "         [-0.0580],\n",
      "         [ 0.1182],\n",
      "         [ 0.0598],\n",
      "         [ 0.1040],\n",
      "         [ 0.0770],\n",
      "         [-0.0924],\n",
      "         [-0.0134],\n",
      "         [-0.1094],\n",
      "         [-0.0636],\n",
      "         [-0.0558],\n",
      "         [ 0.0570],\n",
      "         [-0.0231],\n",
      "         [-0.0002],\n",
      "         [-0.1004],\n",
      "         [-0.0535],\n",
      "         [ 0.0369],\n",
      "         [ 0.0738],\n",
      "         [-0.1046],\n",
      "         [ 0.0150],\n",
      "         [-0.1129],\n",
      "         [ 0.0669],\n",
      "         [ 0.0821],\n",
      "         [ 0.0968],\n",
      "         [-0.0810],\n",
      "         [-0.1198],\n",
      "         [ 0.0388],\n",
      "         [ 0.0965],\n",
      "         [ 0.0923],\n",
      "         [ 0.0459],\n",
      "         [ 0.0380],\n",
      "         [-0.0191],\n",
      "         [ 0.0138],\n",
      "         [ 0.0145],\n",
      "         [ 0.0703],\n",
      "         [ 0.0900],\n",
      "         [-0.0188],\n",
      "         [-0.0859],\n",
      "         [-0.0593],\n",
      "         [-0.1107],\n",
      "         [ 0.0778],\n",
      "         [-0.0335],\n",
      "         [ 0.0069],\n",
      "         [-0.1246],\n",
      "         [ 0.0723],\n",
      "         [-0.0946],\n",
      "         [-0.0812],\n",
      "         [ 0.1086],\n",
      "         [ 0.1229],\n",
      "         [-0.0730],\n",
      "         [ 0.0334],\n",
      "         [-0.0994],\n",
      "         [ 0.1128],\n",
      "         [-0.0149],\n",
      "         [ 0.0986],\n",
      "         [ 0.0681],\n",
      "         [-0.0535],\n",
      "         [ 0.0523],\n",
      "         [ 0.0459],\n",
      "         [-0.0331],\n",
      "         [-0.0360],\n",
      "         [ 0.1053]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.bias | Size: torch.Size([16]) | Values : tensor([ 0.0781, -0.0176], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.1157, -0.1217, -0.0110],\n",
      "         [-0.1035,  0.0693, -0.1027],\n",
      "         [ 0.1391,  0.0052,  0.0959],\n",
      "         [-0.0182,  0.1061,  0.0573],\n",
      "         [-0.0817, -0.1172, -0.1416],\n",
      "         [-0.0878,  0.0058,  0.0697],\n",
      "         [ 0.0271, -0.1073, -0.1339],\n",
      "         [-0.0785, -0.1270,  0.0026],\n",
      "         [ 0.1254, -0.0439,  0.0378],\n",
      "         [-0.1329, -0.0821,  0.0246],\n",
      "         [ 0.0402, -0.1431,  0.0583],\n",
      "         [ 0.1236, -0.1018, -0.0370],\n",
      "         [ 0.0869, -0.1201,  0.0703],\n",
      "         [-0.1443,  0.1049, -0.0100],\n",
      "         [-0.0359,  0.0950, -0.0133],\n",
      "         [ 0.1225, -0.0870, -0.0019]],\n",
      "\n",
      "        [[ 0.1374,  0.0687,  0.0733],\n",
      "         [-0.0294, -0.0890,  0.0798],\n",
      "         [-0.1340,  0.0928, -0.0970],\n",
      "         [-0.1389, -0.1090, -0.1097],\n",
      "         [ 0.0110,  0.1104,  0.1173],\n",
      "         [-0.0464, -0.0013,  0.0588],\n",
      "         [ 0.1404, -0.1078,  0.0534],\n",
      "         [-0.0603, -0.1212, -0.0054],\n",
      "         [ 0.0630,  0.1216, -0.0271],\n",
      "         [-0.1239,  0.0491,  0.0040],\n",
      "         [-0.0886, -0.0028, -0.0474],\n",
      "         [-0.1440,  0.0355, -0.0596],\n",
      "         [ 0.0743,  0.1248,  0.0520],\n",
      "         [-0.0310,  0.0414, -0.1075],\n",
      "         [ 0.0073, -0.0579,  0.0951],\n",
      "         [-0.1005,  0.1389, -0.0506]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0168, -0.1279], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-2.1832e-02],\n",
      "         [ 1.3972e-01],\n",
      "         [-1.6331e-01],\n",
      "         [ 1.1447e-01],\n",
      "         [-5.5830e-02],\n",
      "         [ 1.8807e-01],\n",
      "         [-1.5591e-01],\n",
      "         [-1.6175e-01],\n",
      "         [ 1.1542e-01],\n",
      "         [ 1.0970e-04],\n",
      "         [-1.7931e-01],\n",
      "         [-1.2626e-02],\n",
      "         [-6.9782e-02],\n",
      "         [-8.6840e-02],\n",
      "         [-3.0661e-02],\n",
      "         [-6.9660e-02]],\n",
      "\n",
      "        [[-1.4513e-01],\n",
      "         [ 2.1727e-01],\n",
      "         [-1.0284e-02],\n",
      "         [-1.7308e-01],\n",
      "         [ 2.3803e-01],\n",
      "         [-2.2249e-01],\n",
      "         [-4.1681e-02],\n",
      "         [ 1.1176e-04],\n",
      "         [ 1.9671e-01],\n",
      "         [-6.5561e-03],\n",
      "         [ 1.1496e-01],\n",
      "         [-2.0305e-01],\n",
      "         [-2.1420e-01],\n",
      "         [-1.4524e-01],\n",
      "         [-6.9129e-02],\n",
      "         [-2.2970e-01]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.0979, -0.0412], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0900],\n",
      "         [-0.0543],\n",
      "         [-0.0672],\n",
      "         [-0.1053],\n",
      "         [-0.0866],\n",
      "         [ 0.0082],\n",
      "         [-0.0816],\n",
      "         [-0.0040],\n",
      "         [ 0.0271],\n",
      "         [ 0.0282],\n",
      "         [ 0.0896],\n",
      "         [-0.1041],\n",
      "         [ 0.1029],\n",
      "         [-0.0871],\n",
      "         [ 0.0937],\n",
      "         [ 0.1092],\n",
      "         [ 0.0742],\n",
      "         [ 0.0160],\n",
      "         [ 0.0198],\n",
      "         [ 0.1006],\n",
      "         [ 0.0185],\n",
      "         [ 0.0047],\n",
      "         [-0.0401],\n",
      "         [-0.0513],\n",
      "         [-0.0159],\n",
      "         [-0.0431],\n",
      "         [ 0.1217],\n",
      "         [-0.0106],\n",
      "         [ 0.0050],\n",
      "         [ 0.0523],\n",
      "         [-0.0373],\n",
      "         [-0.0671],\n",
      "         [ 0.1232],\n",
      "         [ 0.0064],\n",
      "         [ 0.0560],\n",
      "         [-0.0449],\n",
      "         [ 0.0963],\n",
      "         [-0.0718],\n",
      "         [ 0.1182],\n",
      "         [-0.0823],\n",
      "         [-0.0377],\n",
      "         [-0.1044],\n",
      "         [ 0.0085],\n",
      "         [-0.0675],\n",
      "         [-0.0044],\n",
      "         [-0.0828],\n",
      "         [-0.0194],\n",
      "         [ 0.0361],\n",
      "         [ 0.0209],\n",
      "         [ 0.0821],\n",
      "         [ 0.0435],\n",
      "         [ 0.0671],\n",
      "         [ 0.0476],\n",
      "         [ 0.0620],\n",
      "         [ 0.0329],\n",
      "         [ 0.0797],\n",
      "         [-0.0856],\n",
      "         [-0.0614],\n",
      "         [-0.0146],\n",
      "         [-0.0373],\n",
      "         [-0.0187],\n",
      "         [ 0.0163],\n",
      "         [-0.0099],\n",
      "         [ 0.0494]],\n",
      "\n",
      "        [[-0.0660],\n",
      "         [-0.0429],\n",
      "         [ 0.0807],\n",
      "         [-0.0520],\n",
      "         [ 0.0846],\n",
      "         [-0.1003],\n",
      "         [ 0.0578],\n",
      "         [-0.0360],\n",
      "         [-0.0749],\n",
      "         [-0.0036],\n",
      "         [-0.0928],\n",
      "         [ 0.0304],\n",
      "         [-0.0681],\n",
      "         [ 0.0960],\n",
      "         [-0.0157],\n",
      "         [ 0.0201],\n",
      "         [-0.0283],\n",
      "         [ 0.0248],\n",
      "         [ 0.0751],\n",
      "         [ 0.0952],\n",
      "         [-0.0254],\n",
      "         [ 0.1218],\n",
      "         [-0.0524],\n",
      "         [ 0.1019],\n",
      "         [-0.1158],\n",
      "         [ 0.0308],\n",
      "         [ 0.0947],\n",
      "         [-0.0866],\n",
      "         [-0.0439],\n",
      "         [-0.0555],\n",
      "         [-0.0172],\n",
      "         [-0.0275],\n",
      "         [-0.1124],\n",
      "         [ 0.0184],\n",
      "         [-0.0100],\n",
      "         [ 0.0737],\n",
      "         [-0.0761],\n",
      "         [ 0.0441],\n",
      "         [-0.0521],\n",
      "         [ 0.1071],\n",
      "         [ 0.0060],\n",
      "         [ 0.0646],\n",
      "         [ 0.0748],\n",
      "         [-0.0292],\n",
      "         [ 0.0221],\n",
      "         [-0.0600],\n",
      "         [-0.1223],\n",
      "         [ 0.0485],\n",
      "         [-0.0253],\n",
      "         [-0.0907],\n",
      "         [-0.0322],\n",
      "         [-0.0654],\n",
      "         [ 0.1183],\n",
      "         [ 0.0706],\n",
      "         [ 0.0499],\n",
      "         [ 0.0024],\n",
      "         [ 0.0508],\n",
      "         [ 0.1228],\n",
      "         [ 0.0852],\n",
      "         [ 0.0196],\n",
      "         [ 0.0728],\n",
      "         [ 0.0210],\n",
      "         [ 0.0320],\n",
      "         [ 0.1177]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.1144,  0.0038], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.weight | Size: torch.Size([2, 768]) | Values : tensor([[-0.0136, -0.0152,  0.0206,  ...,  0.0297, -0.0320, -0.0167],\n",
      "        [ 0.0047, -0.0318, -0.0291,  ..., -0.0068,  0.0267,  0.0351]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.bias | Size: torch.Size([2]) | Values : tensor([ 0.0035, -0.0266], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "model = TinyFallNet().to(device)\n",
    "\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "patience = 20\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation\n",
    "current_acc = 0\n",
    "last_acc = 0\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluate the model with torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    last_acc = current_acc\n",
    "    current_acc = correct\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triggertimes = 0\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "    # Early Stopping\n",
    "    if current_acc <= last_acc:\n",
    "        triggertimes += 1\n",
    "        if triggertimes >= patience:\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "    else:\n",
    "        triggertimes = 0\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlonmcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
