{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import plot_confusion_matrix, plot_confusion_matrix, get_gzipped_model_size, rescale_data\n",
    "from data_organizer_Kfall import DataOrganizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "from keras import models, optimizers, callbacks\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "from models.ConvLSTM import ConvLSTM\n",
    "from models.ConvLSTM_VGG import ConvLSTM_VGG\n",
    "from models.TinyFallNet import TinyFallNet\n",
    "from models.ResNet24 import ResNet24\n",
    "from models.ResNet18 import ResNet18\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config.yaml', 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "\n",
    "#data_path = config['data_path_win']\n",
    "# data_path = config['data_path_linux']\n",
    "data_path = config['data_path_mac']\n",
    "use_saved_data = config['use_saved_data']\n",
    "sensor_data_folder = os.path.join(data_path, 'sensor_data')\n",
    "label_data_folder = os.path.join(data_path, 'label_data')\n",
    "\n",
    "# data mode. Combination of sensor data.\n",
    "# data_mode = 'ACC+GYRO' # 'ACC' or 'ACC+GYRO' or 'ACC+GYRO+MAG'\n",
    "window_size = config['window_size'] # window size\n",
    "fall_threshold = config['fall_threshold'] # threshold for windows labeled as fall\n",
    "num_window_fall_data = config['num_window_fall_data']   # number of windows labeled as fall\n",
    "num_window_not_fall_data = config['num_window_not_fall_data']    # number of windows labeled as not fall\n",
    "acc_max = config['acc_max'] \n",
    "gyro_max = config['gyro_max'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patience:  5\n"
     ]
    }
   ],
   "source": [
    "model_name = \"TinyFallNet_6axis\" # \"ConvLSTM\" or \"ConvLSTM_VGG\" or \"TinyFallNet\" or \"ResNet24\" or \"TinyFallNet_6axis\"\n",
    "# when train_with_int is True, scaled data will be used for training, generate full integer quantized model(int8 input, int8 output)\n",
    "# when train_with_int is False, original data will be used for training, generate three models: dynamic range quantized model(float32 input, float32 output)\n",
    "#                                                                                               full integer quantized model(int8 input, int8 output)\n",
    "#                                                                                               full integer quantized model(float32 input, int8 output)\n",
    "train_with_int = True\n",
    "# use_float_input = True\n",
    "load_from_checkpoint = config['load_from_checkpoint']\n",
    "\n",
    "if not os.path.exists(\"saved_models\"):\n",
    "    os.makedirs(\"saved_models\")\n",
    "\n",
    "if load_from_checkpoint:\n",
    "    model = models.load_model('./saved_models/'+model_name+('_Rescaled' if train_with_int else '')+'.keras')\n",
    "else:\n",
    "    if model_name == \"ConvLSTM\":\n",
    "        model = ConvLSTM()\n",
    "        data_mode = 'ACC+GYRO+MAG' # 'ACC' or 'ACC+GYRO' or 'ACC+GYRO+MAG'\n",
    "    elif model_name == \"ConvLSTM_6axis\":\n",
    "        model = ConvLSTM(6)\n",
    "        data_mode = 'ACC+GYRO'\n",
    "    elif model_name == \"ConvLSTM_VGG\":\n",
    "        model = ConvLSTM_VGG()\n",
    "        data_mode = 'ACC+GYRO+MAG'\n",
    "    elif model_name == \"ConvLSTM_VGG_6axis\":\n",
    "        model = ConvLSTM_VGG(6)\n",
    "        data_mode = 'ACC+GYRO'\n",
    "    elif model_name == \"TinyFallNet\":\n",
    "        model = TinyFallNet()\n",
    "        data_mode = 'ACC+GYRO+MAG'\n",
    "    elif model_name == \"ResNet24\":\n",
    "        model = ResNet24()\n",
    "        data_mode = 'ACC+GYRO+MAG'\n",
    "    elif model_name == \"ResNet24_6axis\":\n",
    "        model = ResNet24(6)\n",
    "        data_mode = 'ACC+GYRO'\n",
    "    elif model_name == \"TinyFallNet_6axis\":\n",
    "        model = TinyFallNet(6)\n",
    "        data_mode = 'ACC+GYRO'\n",
    "    elif model_name == \"ResNet18_6axis\":\n",
    "        model = ResNet18(6)\n",
    "        data_mode = 'ACC+GYRO'\n",
    "    else:\n",
    "        print(\"Please select a valid model name\")\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = config['learning_rate']\n",
    "batch_size = config['batch_size']\n",
    "epochs = config['epochs']\n",
    "lr_factor = config['lr_factor']\n",
    "patience = config['patience']\n",
    "print('patience: ', patience)\n",
    "\n",
    "# create checkpoints folder if not exists\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.makedirs(\"checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/32 folder...\n",
      "Processing 2/32 folder...\n",
      "Processing 3/32 folder...\n",
      "Processing 4/32 folder...\n",
      "Processing 5/32 folder...\n",
      "Processing 6/32 folder...\n",
      "Processing 7/32 folder...\n",
      "Processing 8/32 folder...\n",
      "Processing 9/32 folder...\n",
      "Processing 10/32 folder...\n",
      "Processing 11/32 folder...\n",
      "Processing 12/32 folder...\n",
      "Processing 13/32 folder...\n",
      "Processing 14/32 folder...\n",
      "Processing 15/32 folder...\n",
      "Processing 16/32 folder...\n",
      "Processing 17/32 folder...\n",
      "Processing 18/32 folder...\n",
      "Processing 19/32 folder...\n",
      "Processing 20/32 folder...\n",
      "Processing 21/32 folder...\n",
      "Processing 22/32 folder...\n",
      "Processing 23/32 folder...\n",
      "Processing 24/32 folder...\n",
      "Processing 25/32 folder...\n",
      "Processing 26/32 folder...\n",
      "Processing 27/32 folder...\n",
      "Processing 28/32 folder...\n",
      "Processing 29/32 folder...\n",
      "Processing 30/32 folder...\n",
      "Processing 31/32 folder...\n",
      "Processing 32/32 folder...\n",
      "Data shape:  (75907, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "if not False: #use_saved_data:\n",
    "    data, label = DataOrganizer(sensor_data_folder, \n",
    "                                label_data_folder, \n",
    "                                window_size, \n",
    "                                fall_threshold, \n",
    "                                num_window_fall_data, \n",
    "                                num_window_not_fall_data,\n",
    "                                data_mode)\n",
    "else:\n",
    "    data = np.load('./saved_data/data.npy')\n",
    "    label = np.load('./saved_data/label.npy', allow_pickle=True)\n",
    "    \n",
    "print(\"Data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_saved_data = False\n",
    "if not use_saved_data:\n",
    "    # make sure the rescaling is done only once\n",
    "    if train_with_int==True and data.dtype!=np.int8:\n",
    "        dtype_out = np.int8 # rescaled input data type\n",
    "        data = rescale_data(data, dtype_out, acc_max=acc_max, gyro_max=gyro_max)\n",
    "        np.save('./saved_data/data.npy',data)\n",
    "        np.save('./saved_data/label.npy',label)\n",
    "    else:\n",
    "        data = data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (75907, 50, 6)\n",
      "Data dtype:  int8\n",
      "in_channels:  6\n",
      "not_fall_size:  75060\n",
      "fall_size:  847\n"
     ]
    }
   ],
   "source": [
    "in_channels = data.shape[2]\n",
    "print(\"Data shape: \", data.shape)\n",
    "print(\"Data dtype: \", data.dtype)\n",
    "print('in_channels: ', in_channels)\n",
    "\n",
    "label = label.astype(np.int64)\n",
    "data_copy = data.reshape(data.shape[0], 50, in_channels)\n",
    "\n",
    "B_size = (label == 0).sum()\n",
    "A_size = (label == 1).sum()\n",
    "print('not_fall_size: ', B_size)\t\n",
    "print('fall_size: ', A_size)\n",
    "\n",
    "if not use_saved_data:\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_copy, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Further split the training data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    #print(np.unique(y_train)) # [0 1]\n",
    "    y_train = y_train.astype(np.int64)\n",
    "    y_test = y_test.astype(np.int64)\n",
    "\n",
    "    # select the test data that is not zero\n",
    "    X_test_true = X_test[y_test != 0]\n",
    "    y_test_true = y_test[y_test != 0]\n",
    "    # length of the test data\n",
    "    test_len = X_test_true.shape[0]\n",
    "    X_test_false = X_test[y_test == 0]\n",
    "    y_test_false = y_test[y_test == 0]\n",
    "    # X_test.shape:  (17, 50, 9)\n",
    "    # randomly len number of test data that is zero\n",
    "    index = np.random.choice(X_test_false.shape[0], test_len, replace=False)\n",
    "\n",
    "    X_test_false = X_test[index]\n",
    "    y_test_false = y_test[index]\n",
    "\n",
    "    # concatenate the true and false test data\n",
    "    X_test = np.concatenate((X_test_true, X_test_false), axis=0)\n",
    "    y_test = np.concatenate((y_test_true, y_test_false), axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_saved_data: \n",
    "    # create the saved_data folder if it does not exist\n",
    "    if not os.path.exists('./saved_data'):\n",
    "        os.makedirs('./saved_data')\n",
    "    # save the test data, train data and validation data\n",
    "    np.save('./saved_data/X_test.npy', X_test)\n",
    "    np.save('./saved_data/y_test.npy', y_test)\n",
    "    np.save('./saved_data/X_train.npy', X_train)\n",
    "    np.save('./saved_data/y_train.npy', y_train)\n",
    "    np.save('./saved_data/X_val.npy', X_val)\n",
    "    np.save('./saved_data/y_val.npy', y_val)\n",
    "    \n",
    "else:\n",
    "    X_test = np.load('./saved_data/X_test.npy')\n",
    "    y_test = np.load('./saved_data/y_test.npy')\n",
    "    X_train = np.load('./saved_data/X_train.npy')\n",
    "    y_train = np.load('./saved_data/y_train.npy')\n",
    "    X_val = np.load('./saved_data/X_val.npy')\n",
    "    y_val = np.load('./saved_data/y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1, 50, 6)             0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 1, 48, 64)            1216      ['reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 1, 24, 64)            0         ['conv2d_17[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 1, 24, 16)            1040      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 1, 24, 16)            64        ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 1, 24, 16)            784       ['re_lu_12[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 1, 24, 16)            64        ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 1, 24, 64)            1088      ['re_lu_13[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 1, 24, 64)            256       ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 1, 24, 64)            4160      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 1, 24, 64)            0         ['batch_normalization_14[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)             (None, 1, 24, 64)            0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 1, 24, 16)            1040      ['re_lu_14[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 1, 24, 16)            64        ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_15[0][0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 1, 24, 16)            784       ['re_lu_15[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 1, 24, 16)            64        ['conv2d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 1, 24, 64)            1088      ['re_lu_16[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 1, 24, 64)            256       ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 1, 24, 64)            4160      ['re_lu_14[0][0]']            \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 1, 24, 64)            0         ['batch_normalization_17[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)             (None, 1, 24, 64)            0         ['add_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 1, 24, 16)            1040      ['re_lu_17[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 1, 24, 16)            64        ['conv2d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 1, 24, 16)            784       ['re_lu_18[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 1, 24, 16)            64        ['conv2d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 1, 24, 64)            1088      ['re_lu_19[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 1, 24, 64)            256       ['conv2d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 1, 24, 64)            4160      ['re_lu_17[0][0]']            \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 1, 24, 64)            0         ['batch_normalization_20[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)             (None, 1, 24, 64)            0         ['add_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 1, 24, 16)            1040      ['re_lu_20[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 1, 24, 16)            64        ['conv2d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 1, 24, 16)            784       ['re_lu_21[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 1, 24, 16)            64        ['conv2d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 1, 24, 64)            1088      ['re_lu_22[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 1, 24, 64)            256       ['conv2d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 1, 24, 64)            4160      ['re_lu_20[0][0]']            \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 1, 24, 64)            0         ['batch_normalization_23[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_30[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)             (None, 1, 24, 64)            0         ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (Avera  (None, 1, 12, 64)            0         ['re_lu_23[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 768)                  0         ['average_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 2)                    1538      ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32578 (127.26 KB)\n",
      "Trainable params: 31810 (124.26 KB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate), \n",
    "            loss='categorical_crossentropy',\n",
    "            #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "model.build(input_shape=(None, 50, 9))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape:  (48580, 2)\n",
      "y_val.shape:  (12145, 2)\n",
      "X_train.shape:  (48580, 50, 6)\n",
      "y_train.shape:  (48580, 2)\n"
     ]
    }
   ],
   "source": [
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "if y_train.ndim == 1:\n",
    "    y_train = to_categorical(y_train)\n",
    "if y_val.ndim == 1:\n",
    "    y_val = to_categorical(y_val)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_val.shape: ', y_val.shape)\n",
    "\n",
    "# Define the checkpoint\n",
    "checkpoint_path = './checkpoints/'+model_name+('_Rescaled' if train_with_int else '')+'.chkpt'\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "# Calculate class weights\n",
    "B_multiplier = 1\n",
    "A_multiplier = B_size / A_size\n",
    "class_weight = {0: B_multiplier, 1: A_multiplier}\n",
    "\n",
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)\n",
    "lrs = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=lr_factor, patience=patience, verbose=1)\n",
    "print('X_train.shape: ', X_train.shape) # (23291, 50, 9)\n",
    "print('y_train.shape: ', y_train.shape) # (23291,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val), \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size,\n",
    "          callbacks=[es, lrs, checkpoint],\n",
    "          class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape:  (346, 50, 6)\n",
      "11/11 - 0s - loss: 0.1936 - accuracy: 0.9335 - 497ms/epoch - 45ms/step\n",
      "Test loss: [0.1935845911502838, 0.9335260391235352]\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model(checkpoint_path)\n",
    "# model.load_weights(checkpoint_path)\n",
    "# Evaluate the model\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "if y_test.ndim == 1:\n",
    "    y_test = to_categorical(y_test)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 7ms/step\n",
      "[[162   9]\n",
      " [ 14 161]]\n",
      "Confusion matrix, without normalization\n",
      "[[162   9]\n",
      " [ 14 161]]\n",
      "accuracy:  0.9335260115606936\n",
      "f1_score:  0.9333333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert y_test back to its original form\n",
    "y_test_original = np.argmax(y_test, axis=-1)\n",
    "\n",
    "# Get the model's predictions\n",
    "predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_original, predictions)\n",
    "\n",
    "print(cm)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "\n",
    "# get accuracy\n",
    "accuracy_fp = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "print('accuracy: ', accuracy_fp)\n",
    "# f1 score\n",
    "precision_fp = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "recall_fp = cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "f1_score_fp = 2 * precision_fp * recall_fp / (precision_fp + recall_fp)\n",
    "print('f1_score: ', f1_score_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MARKYI~1\\AppData\\Local\\Temp\\tmpthnqql6z\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MARKYI~1\\AppData\\Local\\Temp\\tmpthnqql6z\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save('./saved_models/'+model_name+('_Rescaled' if train_with_int else '')+'.keras')\n",
    "# convert the model to tflite\n",
    "# saved_model = tf.saved_model.save(model,'saved_models')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "if \"LSTM\" in model_name:\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "# else:\n",
    "#     converter._experimental_lower_tensor_list_ops = False\n",
    "#     converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]}\n",
    "model_tflite = converter.convert()\n",
    "# save the model\n",
    "# open('./saved_models/'+model_name+('_Rescaled' if train_with_int else '')+'.tflite', \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for ConvLSTM model\n",
    "if \"LSTM\" in model_name:\n",
    "    def representative_data_gen():\n",
    "        for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100):\n",
    "            yield [input_value]\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "    if train_with_int:\n",
    "        converter.inference_input_type = tf.int8\n",
    "    else:\n",
    "        converter.inference_input_type = tf.float32\n",
    "    converter.inference_output_type = tf.int8\n",
    " \n",
    "    tflite_q_model = converter.convert()\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_q_model)\n",
    "    input_type = interpreter.get_input_details()[0]['dtype']\n",
    "    print('input: ', input_type)\n",
    "    output_type = interpreter.get_output_details()[0]['dtype']\n",
    "    print('output: ', output_type)\n",
    "    # Save the quantized model to disk\n",
    "    open('./saved_models/'+model_name+'_q.tflite', \"wb\").write(tflite_q_model)\n",
    " \n",
    "    # test the quantized model\n",
    "    if train_with_int:\n",
    "        print('model name: ', model_name)\n",
    "        # Load the model into an interpreter\n",
    "        interpreter = tf.lite.Interpreter(model_path='./saved_models/'+model_name+'_q.tflite')\n",
    "        X_test_qat = X_test.astype('int8')\n",
    "        y_test_qat = y_test.astype('int8')\n",
    "        assert X_test_qat.dtype == np.int8 and y_test_qat.dtype == np.int8\n",
    "    else:\n",
    "        interpreter = tf.lite.Interpreter(model_path='./saved_models/'+model_name+'_q.tflite')\n",
    "        X_test_qat = X_test.astype('float32')\n",
    "        y_test_qat = y_test.astype('int8')\n",
    "        assert X_test_qat.dtype == np.float32 and y_test_qat.dtype == np.int8\n",
    " \n",
    "    # Allocate memory for the model's input Tensor(s)\n",
    "    interpreter.allocate_tensors()\n",
    "    # Get the model input and output details\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    print(\"input: \", input_details)\n",
    "    print(\"output: \", output_details)\n",
    "    predictions = np.zeros(X_test.shape[0])\n",
    "    for i, test_data in enumerate(X_test_qat):\n",
    "        test_data = np.expand_dims(test_data, axis=0)\n",
    "        #print(test_data.shape)\n",
    "        interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "        if i%100 == 0:\n",
    "            # print(\"Evaluated on %d images.\" % test_image_index)\n",
    "            print('Evaluated on ', i, '.')\n",
    "        predictions[i] = output.argmax()\n",
    " \n",
    "    gt = np.argmax(y_test_qat, axis=-1)\n",
    " \n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(gt, predictions)\n",
    " \n",
    "    print(cm)\n",
    "    # plot the confusion matrix\n",
    "    plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    " \n",
    "    accuracy = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "    print('accuracy: ', accuracy)\n",
    " \n",
    "    f1_score = 2 * cm[1][1] / (2 * cm[1][1] + cm[0][1] + cm[1][0])\n",
    "    print('f1_score: ', f1_score)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " quantize_layer_2 (Quantize  (None, 50, 6)                3         ['input_2[0][0]']             \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " quant_reshape_1 (QuantizeW  (None, 1, 50, 6)             1         ['quantize_layer_2[0][0]']    \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_conv2d_17 (QuantizeW  (None, 1, 48, 64)            1347      ['quant_reshape_1[0][0]']     \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_max_pooling2d_1 (Qua  (None, 1, 24, 64)            1         ['quant_conv2d_17[0][0]']     \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_conv2d_19 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_max_pooling2d_1[0][0]'\n",
      " rapperV2)                                                          ]                             \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_19[0][0]']     \n",
      " 12 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_12 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_12\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_20 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_12[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_20[0][0]']     \n",
      " 13 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_13 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_13\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_21 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_13[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_21[0][0]']     \n",
      " 14 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_18 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_max_pooling2d_1[0][0]'\n",
      " rapperV2)                                                          ]                             \n",
      "                                                                                                  \n",
      " quant_add_4 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_14\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_18[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_14 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_4[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_23 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_14[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_23[0][0]']     \n",
      " 15 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_15 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_15\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_24 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_15[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_24[0][0]']     \n",
      " 16 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_16 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_16\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_25 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_16[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_25[0][0]']     \n",
      " 17 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_22 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_re_lu_14[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_5 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_17\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_22[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_17 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_5[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_27 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_17[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_27[0][0]']     \n",
      " 18 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_18 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_18\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_28 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_18[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_28[0][0]']     \n",
      " 19 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_19 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_19\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_29 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_19[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_29[0][0]']     \n",
      " 20 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_26 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_re_lu_17[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_6 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_20\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_26[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_20 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_6[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_31 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_20[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_31[0][0]']     \n",
      " 21 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_21 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_21\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_32 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_21[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_32[0][0]']     \n",
      " 22 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_22 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_22\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_33 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_22[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_33[0][0]']     \n",
      " 23 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_30 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_re_lu_20[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_7 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_23\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_30[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_23 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_7[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_average_pooling2d_1   (None, 1, 12, 64)            3         ['quant_re_lu_23[0][0]']      \n",
      " (QuantizeWrapperV2)                                                                              \n",
      "                                                                                                  \n",
      " quant_flatten_1 (QuantizeW  (None, 768)                  1         ['quant_average_pooling2d_1[0]\n",
      " rapperV2)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " quant_dense_1 (QuantizeWra  (None, 2)                    1543      ['quant_flatten_1[0][0]']     \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34087 (133.15 KB)\n",
      "Trainable params: 31810 (124.26 KB)\n",
      "Non-trainable params: 2277 (8.89 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_model = tfmot.quantization.keras.quantize_model(model)\n",
    "q_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "q_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MARKYI~1\\AppData\\Local\\Temp\\tmpsbt6ossl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MARKYI~1\\AppData\\Local\\Temp\\tmpsbt6ossl\\assets\n",
      "c:\\Anaconda3\\envs\\mlonmcu\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68952"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model.save('./saved_models/'+model_name+'_q'+('_Rescaled' if train_with_int else '')+'.keras')\n",
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "# Set up the converter for quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "if not train_with_int:\n",
    "  # Dynamic Range Quantization\n",
    "  tflite_q_model = converter.convert()\n",
    "  open('./saved_models/'+model_name+'_q_dynR.tflite', \"wb\").write(tflite_q_model)\n",
    "  # Full Integer Quantization(float input)\n",
    "  converter.representative_dataset = representative_data_gen\n",
    "  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "  converter.inference_input_type = tf.float32\n",
    "  converter.inference_output_type = tf.int8\n",
    "  tflite_q_model = converter.convert()\n",
    "  open('./saved_models/'+model_name+'_q_FullInt_FPInput.tflite', \"wb\").write(tflite_q_model)\n",
    "\n",
    "# Full Integer Quantization(int input)\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8 # Convert output to int8\n",
    "tflite_q_model = converter.convert()\n",
    "open('./saved_models/'+model_name+'_q_FullInt'+('_Rescaled' if train_with_int else '')+'.tflite', \"wb\").write(tflite_q_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(346,)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name:  TinyFallNet_6axis\n",
      "input:  {'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([ 1, 50,  6]), 'shape_signature': array([-1, 50,  6]), 'dtype': <class 'numpy.int8'>, 'quantization': (3.921568847431445e-09, -1), 'quantization_parameters': {'scales': array([3.921569e-09], dtype=float32), 'zero_points': array([-1]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "output:  {'name': 'StatefulPartitionedCall:0', 'index': 72, 'shape': array([1, 2]), 'shape_signature': array([-1,  2]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Evaluated on  0 .\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "Evaluated on  100 .\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "Evaluated on  200 .\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "Evaluated on  300 .\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[-125  125]\n",
      "[[  0 171]\n",
      " [  0 175]]\n",
      "Confusion matrix, without normalization\n",
      "[[  0 171]\n",
      " [  0 175]]\n",
      "accuracy:  0.5057803468208093\n",
      "f1_score:  0.6717850287907869\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the quantized model\n",
    "if train_with_int:\n",
    "    print('model name: ', model_name)\n",
    "    # Load the model into an interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path='./saved_models/'+model_name+'_q_FullInt_Rescaled.tflite')\n",
    "    X_test_qat = X_test.astype('int8')\n",
    "    y_test_qat = y_test.astype('int8')\n",
    "    assert X_test_qat.dtype == np.int8 and y_test_qat.dtype == np.int8\n",
    "else:\n",
    "    interpreter = tf.lite.Interpreter(model_path='./saved_models/'+model_name+'_q_FullInt_FPInput.tflite')\n",
    "    X_test_qat = X_test.astype('float32')\n",
    "    y_test_qat = y_test.astype('int8')\n",
    "    assert X_test_qat.dtype == np.float32 and y_test_qat.dtype == np.int8\n",
    "\n",
    "# Allocate memory for the model's input Tensor(s)\n",
    "interpreter.allocate_tensors()\n",
    "# Get the model input and output details\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(\"input: \", input_details)\n",
    "print(\"output: \", output_details)\n",
    "predictions = np.zeros(X_test.shape[0])\n",
    "for i, test_data in enumerate(X_test_qat):\n",
    "    test_data = np.expand_dims(test_data, axis=0)\n",
    "    #print(test_data.shape)\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    if i%100 == 0:\n",
    "        # print(\"Evaluated on %d images.\" % test_image_index)\n",
    "        print('Evaluated on ', i, '.')\n",
    "    predictions[i] = output.argmax()\n",
    "    print(output)\n",
    "\n",
    "gt = np.argmax(y_test_qat, axis=-1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(gt, predictions)\n",
    "\n",
    "print(cm)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "\n",
    "# get accuracy\n",
    "accuracy_fp = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "print('accuracy: ', accuracy_fp)\n",
    "\n",
    "f1_score = 2 * cm[1][1] / (2 * cm[1][1] + cm[0][1] + cm[1][0])\n",
    "print('f1_score: ', f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape:  (48580, 2)\n",
      "y_val.shape:  (12145, 2)\n"
     ]
    }
   ],
   "source": [
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "if y_train.ndim == 1:\n",
    "    y_train = to_categorical(y_train)\n",
    "if y_val.ndim == 1:\n",
    "    y_val = to_categorical(y_val)\n",
    "\n",
    "if train_with_int:\n",
    "    assert X_train.dtype == np.int8\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_val.shape: ', y_val.shape)\n",
    "# Define the checkpoint\n",
    "checkpoint_qat_path = './checkpoints/'+model_name+'_qat'+('_Rescaled' if train_with_int else '')+'.chkpt'\n",
    "checkpoint_qat = ModelCheckpoint(checkpoint_qat_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_history = q_model.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs, checkpoint_qat],\n",
    "            class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MARKYI~1\\AppData\\Local\\Temp\\tmpm9zd04kr\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MARKYI~1\\AppData\\Local\\Temp\\tmpm9zd04kr\\assets\n",
      "c:\\Anaconda3\\envs\\mlonmcu\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63480"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# q_model.load_weights(checkpoint_qat_path)\n",
    "q_model = models.load_model(checkpoint_qat_path)\n",
    "\n",
    "q_model.save('./saved_models/'+model_name+'_qat'+('_Rescaled' if train_with_int else '')+'.keras')\n",
    "\n",
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "# Set up the converter for quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "if not train_with_int:\n",
    "  # Dynamic Range Quantization\n",
    "  tflite_q_model = converter.convert()\n",
    "  open('./saved_models/'+model_name+'_qat_dynR.tflite', \"wb\").write(tflite_q_model)\n",
    "  # Full Integer Quantization(float input)\n",
    "  converter.representative_dataset = representative_data_gen\n",
    "  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "  converter.inference_input_type = tf.float32\n",
    "  converter.inference_output_type = tf.int8\n",
    "  tflite_q_model = converter.convert()\n",
    "  open('./saved_models/'+model_name+'_qat_FullInt_FPInput.tflite', \"wb\").write(tflite_q_model)\n",
    "\n",
    "# Full Integer Quantization(int input)\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8 # Convert output to int8\n",
    "tflite_q_model = converter.convert()\n",
    "open('./saved_models/'+model_name+'_qat_FullInt'+('_Rescaled' if train_with_int else '')+'.tflite', \"wb\").write(tflite_q_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name:  TinyFallNet_6axis\n",
      "input:  {'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([ 1, 50,  6]), 'shape_signature': array([-1, 50,  6]), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "output:  {'name': 'StatefulPartitionedCall:0', 'index': 73, 'shape': array([1, 2]), 'shape_signature': array([-1,  2]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Evaluated on  0 .\n",
      "Evaluated on  100 .\n",
      "Evaluated on  200 .\n",
      "Evaluated on  300 .\n",
      "[[164   7]\n",
      " [  4 171]]\n",
      "Confusion matrix, without normalization\n",
      "[[164   7]\n",
      " [  4 171]]\n",
      "accuracy:  0.9682080924855492\n",
      "f1_score:  0.9688385269121813\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the quantized model\n",
    "if train_with_int:\n",
    "    print('model name: ', model_name)\n",
    "    # Load the model into an interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path='./saved_models/'+model_name+'_qat_FullInt_Rescaled.tflite')\n",
    "    X_test_qat = X_test.astype('int8')\n",
    "    y_test_qat = y_test.astype('int8')\n",
    "    assert X_test_qat.dtype == np.int8 and y_test_qat.dtype == np.int8\n",
    "else:\n",
    "    interpreter = tf.lite.Interpreter(model_path='./saved_models/'+model_name+'_qat_FullInt_FPInput.tflite')\n",
    "    X_test_qat = X_test.astype('float32')\n",
    "    y_test_qat = y_test.astype('int8')\n",
    "    assert X_test_qat.dtype == np.float32 and y_test_qat.dtype == np.int8\n",
    "\n",
    "# Allocate memory for the model's input Tensor(s)\n",
    "interpreter.allocate_tensors()\n",
    "# Get the model input and output details\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(\"input: \", input_details)\n",
    "print(\"output: \", output_details)\n",
    "predictions = np.zeros(X_test.shape[0])\n",
    "for i, test_data in enumerate(X_test_qat):\n",
    "    test_data = np.expand_dims(test_data, axis=0)\n",
    "    #print(test_data.shape)\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    if i%100 == 0:\n",
    "        # print(\"Evaluated on %d images.\" % test_image_index)\n",
    "        print('Evaluated on ', i, '.')\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "gt = np.argmax(y_test_qat, axis=-1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(gt, predictions)\n",
    "\n",
    "print(cm)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "\n",
    "# get accuracy\n",
    "accuracy_fp = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "print('accuracy: ', accuracy_fp)\n",
    "\n",
    "f1_score = 2 * cm[1][1] / (2 * cm[1][1] + cm[0][1] + cm[1][0])\n",
    "print('f1_score: ', f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_reshap  (None, 1, 50, 6)             1         ['input_2[0][0]']             \n",
      " e_1 (PruneLowMagnitude)                                                                          \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 48, 64)            2370      ['prune_low_magnitude_reshape_\n",
      " _17 (PruneLowMagnitude)                                            1[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_max_po  (None, 1, 24, 64)            1         ['prune_low_magnitude_conv2d_1\n",
      " oling2d_1 (PruneLowMagnitu                                         7[0][0]']                     \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_max_pool\n",
      " _19 (PruneLowMagnitude)                                            ing2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_1\n",
      " normalization_12 (PruneLow                                         9[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 12 (PruneLowMagnitude)                                             rmalization_12[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_12\n",
      " _20 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_2\n",
      " normalization_13 (PruneLow                                         0[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 13 (PruneLowMagnitude)                                             rmalization_13[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_13\n",
      " _21 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_2\n",
      " normalization_14 (PruneLow                                         1[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_max_pool\n",
      " _18 (PruneLowMagnitude)                                            ing2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_4   (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_14[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_1\n",
      "                                                                    8[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add_4[0]\n",
      " 14 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_re_lu_14\n",
      " _23 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_2\n",
      " normalization_15 (PruneLow                                         3[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 15 (PruneLowMagnitude)                                             rmalization_15[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_15\n",
      " _24 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_2\n",
      " normalization_16 (PruneLow                                         4[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 16 (PruneLowMagnitude)                                             rmalization_16[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_16\n",
      " _25 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_2\n",
      " normalization_17 (PruneLow                                         5[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_re_lu_14\n",
      " _22 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_5   (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_17[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_2\n",
      "                                                                    2[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add_5[0]\n",
      " 17 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_re_lu_17\n",
      " _27 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_2\n",
      " normalization_18 (PruneLow                                         7[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 18 (PruneLowMagnitude)                                             rmalization_18[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_18\n",
      " _28 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_2\n",
      " normalization_19 (PruneLow                                         8[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 19 (PruneLowMagnitude)                                             rmalization_19[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_19\n",
      " _29 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_2\n",
      " normalization_20 (PruneLow                                         9[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_re_lu_17\n",
      " _26 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_6   (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_20[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_2\n",
      "                                                                    6[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add_6[0]\n",
      " 20 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_re_lu_20\n",
      " _31 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_3\n",
      " normalization_21 (PruneLow                                         1[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 21 (PruneLowMagnitude)                                             rmalization_21[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_21\n",
      " _32 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_3\n",
      " normalization_22 (PruneLow                                         2[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 22 (PruneLowMagnitude)                                             rmalization_22[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_22\n",
      " _33 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_3\n",
      " normalization_23 (PruneLow                                         3[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_re_lu_20\n",
      " _30 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_7   (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_23[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_3\n",
      "                                                                    0[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add_7[0]\n",
      " 23 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_averag  (None, 1, 12, 64)            1         ['prune_low_magnitude_re_lu_23\n",
      " e_pooling2d_1 (PruneLowMag                                         [0][0]']                      \n",
      " nitude)                                                                                          \n",
      "                                                                                                  \n",
      " prune_low_magnitude_flatte  (None, 768)                  1         ['prune_low_magnitude_average_\n",
      " n_1 (PruneLowMagnitude)                                            pooling2d_1[0][0]']           \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_  (None, 2)                    3076      ['prune_low_magnitude_flatten_\n",
      " 1 (PruneLowMagnitude)                                              1[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 62982 (246.22 KB)\n",
      "Trainable params: 31810 (124.26 KB)\n",
      "Non-trainable params: 31172 (121.96 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Unstrucutred pruning with constant sparsity\n",
    "pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=2000, frequency=100),\n",
    "}\n",
    "\n",
    "ups = pruning_callbacks.UpdatePruningStep()\n",
    "# Create a pruning model\n",
    "pruned_model_unstructured = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "pruned_model_unstructured.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_model_unstructured.summary()\n",
    "\n",
    "checkpoint_prune_path = './checkpoints/'+model_name+'_pruned_unstructured'+('_Rescaled' if train_with_int else '')+'.chkpt'\n",
    "# Define the checkpoint\n",
    "checkpoint_prune = ModelCheckpoint(checkpoint_prune_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model_unstructured.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs, ups, checkpoint_prune],\n",
    "            class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model loss:  0.10467583686113358\n",
      "Pruned model accuracy:  0.9624277353286743\n",
      "Full-precision model accuracy:  0.9682080924855492\n"
     ]
    }
   ],
   "source": [
    "# load the best model\n",
    "pruned_model_unstructured = models.load_model(checkpoint_prune_path)\n",
    "# pruned_model_unstructured.load_weights(checkpoint_prune_path)\n",
    "# evaluate the model on the test set\n",
    "pruned_loss_unstructured, pruned_acc_unstructured = pruned_model_unstructured.evaluate(X_test, y_test, verbose=0)\n",
    "print('Pruned model loss: ', pruned_loss_unstructured)\n",
    "print('Pruned model accuracy: ', pruned_acc_unstructured)\n",
    "print('Full-precision model accuracy: ', accuracy_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MARKYI~1\\AppData\\Local\\Temp\\tmpgmxrwjeq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MARKYI~1\\AppData\\Local\\Temp\\tmpgmxrwjeq\\assets\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "pruned_model_unstructured.save('./saved_models/'+model_name+'_pruned_unstructured'+('_Rescaled' if train_with_int else '')+'.keras')  # The file needs to end with the .keras extension\n",
    "#print('Saved pruned Keras model to:', os.path.abspath(pruned_keras_file_unstructured))\n",
    "\n",
    "# Conversion to TF Lite\n",
    "pruned_model_unstructured_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model_unstructured)\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model_unstructured_for_export)\n",
    "pruned_tflite_model_unstructured = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "pruned_tflite_file_unstructured = './saved_models/'+model_name+'_pruned_unstructured'+('_Rescaled' if train_with_int else '')+'.tflite'\n",
    "\n",
    "with open(pruned_tflite_file_unstructured, 'wb') as f:\n",
    "    f.write(pruned_tflite_model_unstructured)\n",
    "\n",
    "# print('Saved pruned TFLite model to:', os.path.abspath(pruned_tflite_file_unstructured))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the unstructured pruned model:  92068\n",
      "Size of the full-precision model:  700000\n",
      "The achieved compression ratio is 7.60x\n"
     ]
    }
   ],
   "source": [
    "# compare the size of the pruned model and the full-precision model\n",
    "unstructured_pruned_model_path = './saved_models/'+model_name+'_pruned_unstructured'+('_Rescaled' if train_with_int else '')+'.tflite'\n",
    "full_prec_model_path = './saved_models/'+model_name+('_Rescaled' if train_with_int else '')+'.tflite'\n",
    "print('Size of the unstructured pruned model: ', get_gzipped_model_size(unstructured_pruned_model_path))\n",
    "# print('Size of the full-precision model: ', get_gzipped_model_size(full_prec_model_path))\n",
    "print('Size of the full-precision model: ', 700*1000)\n",
    "\n",
    "print(\"The achieved compression ratio is %.2fx\" % (700*1000 / get_gzipped_model_size(unstructured_pruned_model_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PQAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " quantize_layer_6 (Quantize  (None, 50, 6)                3         ['input_2[0][0]']             \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " quant_reshape_1 (QuantizeW  (None, 1, 50, 6)             1         ['quantize_layer_6[0][0]']    \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_conv2d_17 (QuantizeW  (None, 1, 48, 64)            1347      ['quant_reshape_1[0][0]']     \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_max_pooling2d_1 (Qua  (None, 1, 24, 64)            1         ['quant_conv2d_17[0][0]']     \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_conv2d_19 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_max_pooling2d_1[0][0]'\n",
      " rapperV2)                                                          ]                             \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_19[0][0]']     \n",
      " 12 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_12 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_12\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_20 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_12[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_20[0][0]']     \n",
      " 13 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_13 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_13\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_21 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_13[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_21[0][0]']     \n",
      " 14 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_18 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_max_pooling2d_1[0][0]'\n",
      " rapperV2)                                                          ]                             \n",
      "                                                                                                  \n",
      " quant_add_4 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_14\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_18[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_14 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_4[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_23 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_14[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_23[0][0]']     \n",
      " 15 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_15 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_15\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_24 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_15[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_24[0][0]']     \n",
      " 16 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_16 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_16\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_25 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_16[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_25[0][0]']     \n",
      " 17 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_22 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_re_lu_14[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_5 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_17\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_22[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_17 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_5[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_27 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_17[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_27[0][0]']     \n",
      " 18 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_18 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_18\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_28 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_18[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_28[0][0]']     \n",
      " 19 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_19 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_19\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_29 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_19[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_29[0][0]']     \n",
      " 20 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_26 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_re_lu_17[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_6 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_20\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_26[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_20 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_6[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_31 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_20[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_31[0][0]']     \n",
      " 21 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_21 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_21\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_32 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_21[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_32[0][0]']     \n",
      " 22 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_22 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_22\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_33 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_22[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_33[0][0]']     \n",
      " 23 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_30 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_re_lu_20[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_7 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_23\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_30[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_23 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_7[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_average_pooling2d_1   (None, 1, 12, 64)            3         ['quant_re_lu_23[0][0]']      \n",
      " (QuantizeWrapperV2)                                                                              \n",
      "                                                                                                  \n",
      " quant_flatten_1 (QuantizeW  (None, 768)                  1         ['quant_average_pooling2d_1[0]\n",
      " rapperV2)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " quant_dense_1 (QuantizeWra  (None, 2)                    1543      ['quant_flatten_1[0][0]']     \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34087 (133.15 KB)\n",
      "Trainable params: 31810 (124.26 KB)\n",
      "Non-trainable params: 2277 (8.89 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# PQAT\n",
    "\n",
    "\n",
    "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
    "              pruned_model_unstructured_for_export)\n",
    "\n",
    "\n",
    "\n",
    "pruned_qat_model = tfmot.quantization.keras.quantize_apply(quant_aware_annotate_model,\n",
    "                   tfmot.experimental.combine.Default8BitPrunePreserveQuantizeScheme())\n",
    "\n",
    "pruned_qat_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_qat_model.summary()\n",
    "\n",
    "checkpoint_pqat_path = './checkpoints/'+model_name+'_pqat'+('_Rescaled' if train_with_int else '')+'.chkpt'\n",
    "\n",
    "checkpoint_pqat = ModelCheckpoint(checkpoint_pqat_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (48580, 50, 6)\n",
      "y_train.shape:  (48580, 2)\n",
      "Epoch 1/50\n",
      "760/760 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.9487\n",
      "Epoch 1: val_loss improved from inf to 0.10590, saving model to ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 74s 87ms/step - loss: 0.2789 - accuracy: 0.9487 - val_loss: 0.1059 - val_accuracy: 0.9662 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "759/760 [============================>.] - ETA: 0s - loss: 0.2048 - accuracy: 0.9579\n",
      "Epoch 2: val_loss improved from 0.10590 to 0.09384, saving model to ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 73s 96ms/step - loss: 0.2048 - accuracy: 0.9579 - val_loss: 0.0938 - val_accuracy: 0.9657 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "759/760 [============================>.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9640\n",
      "Epoch 3: val_loss improved from 0.09384 to 0.09051, saving model to ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 79s 104ms/step - loss: 0.1631 - accuracy: 0.9640 - val_loss: 0.0905 - val_accuracy: 0.9696 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "759/760 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9696\n",
      "Epoch 4: val_loss did not improve from 0.09051\n",
      "760/760 [==============================] - 61s 80ms/step - loss: 0.1398 - accuracy: 0.9696 - val_loss: 0.1403 - val_accuracy: 0.9596 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "759/760 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 0.9664\n",
      "Epoch 5: val_loss improved from 0.09051 to 0.08091, saving model to ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\n",
      "INFO:tensorflow:Assets written to: ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\TinyFallNet_6axis_pqat_Rescaled.chkpt\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760/760 [==============================] - 77s 101ms/step - loss: 0.1703 - accuracy: 0.9664 - val_loss: 0.0809 - val_accuracy: 0.9767 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "759/760 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 0.9651\n",
      "Epoch 6: val_loss did not improve from 0.08091\n",
      "760/760 [==============================] - 63s 82ms/step - loss: 0.1815 - accuracy: 0.9651 - val_loss: 0.1063 - val_accuracy: 0.9695 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "759/760 [============================>.] - ETA: 0s - loss: 0.1858 - accuracy: 0.9647\n",
      "Epoch 7: val_loss did not improve from 0.08091\n",
      "760/760 [==============================] - 67s 88ms/step - loss: 0.1858 - accuracy: 0.9647 - val_loss: 0.1891 - val_accuracy: 0.9401 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "759/760 [============================>.] - ETA: 0s - loss: 0.2594 - accuracy: 0.9581\n",
      "Epoch 8: val_loss did not improve from 0.08091\n",
      "760/760 [==============================] - 62s 81ms/step - loss: 0.2594 - accuracy: 0.9581 - val_loss: 0.1652 - val_accuracy: 0.9560 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "759/760 [============================>.] - ETA: 0s - loss: 0.1672 - accuracy: 0.9667\n",
      "Epoch 9: val_loss did not improve from 0.08091\n",
      "760/760 [==============================] - 62s 81ms/step - loss: 0.1672 - accuracy: 0.9667 - val_loss: 0.0826 - val_accuracy: 0.9759 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "759/760 [============================>.] - ETA: 0s - loss: 0.1219 - accuracy: 0.9763\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.08091\n",
      "760/760 [==============================] - 61s 81ms/step - loss: 0.1219 - accuracy: 0.9763 - val_loss: 0.1079 - val_accuracy: 0.9643 - lr: 5.0000e-04\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b2acf4ebe0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('X_train.shape: ', X_train.shape) # (16362, 50, 9)\n",
    "print('y_train.shape: ', y_train.shape) # (16362, 2)\n",
    "if train_with_int:\n",
    "    assert X_train.dtype == np.int8\n",
    "    \n",
    "pruned_qat_model.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs, ups, checkpoint_pqat],\n",
    "            class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MARKYI~1\\AppData\\Local\\Temp\\tmpuly67cl6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\MARKYI~1\\AppData\\Local\\Temp\\tmpuly67cl6\\assets\n",
      "c:\\Anaconda3\\envs\\mlonmcu\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63480"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the best model\n",
    "pruned_qat_model = models.load_model(checkpoint_pqat_path)\n",
    "# pruned_qat_model.load_weights(checkpoint_pqat_path)\n",
    "\n",
    "pruned_qat_model.save('./saved_models/'+model_name+'_pqat'+('_Rescaled' if train_with_int else '')+'.keras')  # The file needs to end with the .keras extension\n",
    "\n",
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "# Set up the converter for quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_qat_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "if not train_with_int:\n",
    "  # Dynamic Range Quantization\n",
    "  pruned_qat_tflite_model = converter.convert()\n",
    "  open('./saved_models/'+model_name+'_pqat_dynR.tflite', \"wb\").write(pruned_qat_tflite_model)\n",
    "  # Full Integer Quantization(float input)\n",
    "  converter.representative_dataset = representative_data_gen\n",
    "  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "  converter.inference_input_type = tf.float32\n",
    "  converter.inference_output_type = tf.int8\n",
    "  pruned_qat_tflite_model = converter.convert()\n",
    "  open('./saved_models/'+model_name+'_pqat_FullInt_FPInput.tflite', \"wb\").write(pruned_qat_tflite_model)\n",
    "\n",
    "# Full Integer Quantization(int input)\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8 # Convert output to int8\n",
    "pruned_qat_tflite_model = converter.convert()\n",
    "open('./saved_models/'+model_name+'_pqat_FullInt'+('_Rescaled' if train_with_int else '') +'.tflite', \"wb\").write(pruned_qat_tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name:  TinyFallNet_6axis\n",
      "input:  {'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([ 1, 50,  6]), 'shape_signature': array([-1, 50,  6]), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "output:  {'name': 'StatefulPartitionedCall:0', 'index': 73, 'shape': array([1, 2]), 'shape_signature': array([-1,  2]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Evaluated on  0 .\n",
      "Evaluated on  100 .\n",
      "Evaluated on  200 .\n",
      "Evaluated on  300 .\n",
      "[[162   9]\n",
      " [  7 168]]\n",
      "accuracy:  0.953757225433526\n",
      "Confusion matrix, without normalization\n",
      "[[162   9]\n",
      " [  7 168]]\n",
      "f1_score:  0.9545454545454546\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAHpCAYAAAChumdzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQOElEQVR4nO3deVhU9f4H8PcZkAGRGRaFgUTADXFfM8Q1Sdw1LbUowTWvW+5LhgIupLliLln+VEyvaW6p5Z7igqa4K+GupAIpAoKxyJzfH16mRlAZZmDmOO/Xfc7zON9z5pzP4ZK9+y7nCKIoiiAiIiIyYTJjF0BERET0OgwsREREZPIYWIiIiMjkMbAQERGRyWNgISIiIpPHwEJEREQmj4GFiIiITB4DCxEREZk8BhYiIiIyeQwsRBJ37do1tGvXDkqlEoIgYNu2bQY9/+3btyEIAlavXm3Q80pZ69at0bp1a2OXQWRWGFiIDODGjRv47LPPULlyZVhbW0OhUMDPzw+LFi3C33//XaLXDgoKwsWLFzFz5kysXbsWjRs3LtHrlabg4GAIggCFQlHoz/HatWsQBAGCIGDu3Lk6n//+/fsIDQ3FuXPnDFAtEZUkS2MXQCR1u3btwocffgi5XI6+ffuidu3ayMnJwdGjRzF+/HhcvnwZK1asKJFr//3334iJicGUKVMwfPjwErmGh4cH/v77b5QpU6ZEzv86lpaWePr0KXbs2IFevXpp7Vu3bh2sra2RlZVVrHPfv38fYWFh8PT0RP369Yv8vb179xbrekRUfAwsRHq4desW+vTpAw8PDxw8eBCurq6afcOGDcP169exa9euErv+X3/9BQCwt7cvsWsIggBra+sSO//ryOVy+Pn54b///W+BwLJ+/Xp06tQJmzdvLpVanj59irJly8LKyqpUrkdE/+CQEJEe5syZg4yMDKxcuVIrrOSrWrUqPv/8c83nZ8+eYfr06ahSpQrkcjk8PT3xxRdfIDs7W+t7np6e6Ny5M44ePYq3334b1tbWqFy5MqKiojTHhIaGwsPDAwAwfvx4CIIAT09PAM+HUvL//G+hoaEQBEGrbd++fWjevDns7e1Rrlw5eHt744svvtDsf9kcloMHD6JFixawtbWFvb09unXrhri4uEKvd/36dQQHB8Pe3h5KpRL9+vXD06dPX/6DfcHHH3+MX3/9FampqZq2U6dO4dq1a/j4448LHJ+SkoJx48ahTp06KFeuHBQKBTp06IDz589rjjl06BCaNGkCAOjXr59maCn/Plu3bo3atWsjNjYWLVu2RNmyZTU/lxfnsAQFBcHa2rrA/QcEBMDBwQH3798v8r0SUeEYWIj0sGPHDlSuXBnNmjUr0vEDBw7E1KlT0bBhQyxYsACtWrVCREQE+vTpU+DY69ev44MPPsB7772HefPmwcHBAcHBwbh8+TIAoEePHliwYAEA4KOPPsLatWuxcOFCneq/fPkyOnfujOzsbISHh2PevHno2rUrjh079srv7d+/HwEBAUhOTkZoaCjGjBmD48ePw8/PD7dv3y5wfK9evfDkyRNERESgV69eWL16NcLCwopcZ48ePSAIArZs2aJpW79+PWrUqIGGDRsWOP7mzZvYtm0bOnfujPnz52P8+PG4ePEiWrVqpQkPPj4+CA8PBwAMHjwYa9euxdq1a9GyZUvNeR49eoQOHTqgfv36WLhwIdq0aVNofYsWLUKFChUQFBSEvLw8AMC3336LvXv3YvHixXBzcyvyvRLRS4hEVCxpaWkiALFbt25FOv7cuXMiAHHgwIFa7ePGjRMBiAcPHtS0eXh4iADE6OhoTVtycrIol8vFsWPHatpu3bolAhC//vprrXMGBQWJHh4eBWqYNm2a+O9/7BcsWCACEP/666+X1p1/jVWrVmna6tevLzo7O4uPHj3StJ0/f16UyWRi3759C1yvf//+Wud8//33RScnp5de89/3YWtrK4qiKH7wwQdi27ZtRVEUxby8PFGlUolhYWGF/gyysrLEvLy8Avchl8vF8PBwTdupU6cK3Fu+Vq1aiQDE5cuXF7qvVatWWm179uwRAYgzZswQb968KZYrV07s3r37a++RiIqGPSxExZSeng4AsLOzK9Lxv/zyCwBgzJgxWu1jx44FgAJzXWrWrIkWLVpoPleoUAHe3t64efNmsWt+Uf7cl+3bt0OtVhfpOw8ePMC5c+cQHBwMR0dHTXvdunXx3nvvae7z34YMGaL1uUWLFnj06JHmZ1gUH3/8MQ4dOoTExEQcPHgQiYmJhQ4HAc/nvchkz/96y8vLw6NHjzTDXWfOnCnyNeVyOfr161ekY9u1a4fPPvsM4eHh6NGjB6ytrfHtt98W+VpE9GoMLETFpFAoAABPnjwp0vF37tyBTCZD1apVtdpVKhXs7e1x584drfZKlSoVOIeDgwMeP35czIoL6t27N/z8/DBw4EC4uLigT58+2Lhx4yvDS36d3t7eBfb5+Pjg4cOHyMzM1Gp/8V4cHBwAQKd76dixI+zs7PDjjz9i3bp1aNKkSYGfZT61Wo0FCxagWrVqkMvlKF++PCpUqIALFy4gLS2tyNd86623dJpgO3fuXDg6OuLcuXOIjIyEs7Nzkb9LRK/GwEJUTAqFAm5ubrh06ZJO33tx0uvLWFhYFNouimKxr5E/vyKfjY0NoqOjsX//fnz66ae4cOECevfujffee6/AsfrQ517yyeVy9OjRA2vWrMHWrVtf2rsCALNmzcKYMWPQsmVL/PDDD9izZw/27duHWrVqFbknCXj+89HF2bNnkZycDAC4ePGiTt8loldjYCHSQ+fOnXHjxg3ExMS89lgPDw+o1Wpcu3ZNqz0pKQmpqamaFT+G4ODgoLWiJt+LvTgAIJPJ0LZtW8yfPx9XrlzBzJkzcfDgQfz222+Fnju/zvj4+AL7/vjjD5QvXx62trb63cBLfPzxxzh79iyePHlS6ETlfD/99BPatGmDlStXok+fPmjXrh38/f0L/EyKGh6LIjMzE/369UPNmjUxePBgzJkzB6dOnTLY+YnMHQMLkR4mTJgAW1tbDBw4EElJSQX237hxA4sWLQLwfEgDQIGVPPPnzwcAdOrUyWB1ValSBWlpabhw4YKm7cGDB9i6davWcSkpKQW+m/8AtReXWudzdXVF/fr1sWbNGq0AcOnSJezdu1dznyWhTZs2mD59Or755huoVKqXHmdhYVGg92bTpk24d++eVlt+sCos3Olq4sSJuHv3LtasWYP58+fD09MTQUFBL/05EpFu+OA4Ij1UqVIF69evR+/eveHj46P1pNvjx49j06ZNCA4OBgDUq1cPQUFBWLFiBVJTU9GqVSv8/vvvWLNmDbp37/7SJbPF0adPH0ycOBHvv/8+Ro4ciadPn2LZsmWoXr261qTT8PBwREdHo1OnTvDw8EBycjKWLl2KihUronnz5i89/9dff40OHTrA19cXAwYMwN9//43FixdDqVQiNDTUYPfxIplMhi+//PK1x3Xu3Bnh4eHo168fmjVrhosXL2LdunWoXLmy1nFVqlSBvb09li9fDjs7O9ja2qJp06bw8vLSqa6DBw9i6dKlmDZtmmaZ9apVq9C6dWuEhIRgzpw5Op2PiAph5FVKRG+Eq1evioMGDRI9PT1FKysr0c7OTvTz8xMXL14sZmVlaY7Lzc0Vw8LCRC8vL7FMmTKiu7u7OHnyZK1jRPH5suZOnToVuM6Ly2lftqxZFEVx7969Yu3atUUrKyvR29tb/OGHHwosaz5w4IDYrVs30c3NTbSyshLd3NzEjz76SLx69WqBa7y49Hf//v2in5+faGNjIyoUCrFLly7ilStXtI7Jv96Ly6ZXrVolAhBv3br10p+pKGova36Zly1rHjt2rOjq6ira2NiIfn5+YkxMTKHLkbdv3y7WrFlTtLS01LrPVq1aibVq1Sr0mv8+T3p6uujh4SE2bNhQzM3N1Tpu9OjRokwmE2NiYl55D0T0eoIo6jDrjYiIiMgIOIeFiIiITB4DCxEREZk8BhYiIiIyeQwsREREZPIYWIiIiMjkMbAQERGRyeOD40qJWq3G/fv3YWdnZ9DHgRMRUekSRRFPnjyBm5ub5q3gJS0rKws5OTkGOZeVlRWsra0Ncq7SxMBSSu7fvw93d3djl0FERAaSkJCAihUrlvh1srKyYGPnBDx7apDzqVQq3Lp1S3KhhYGllNjZ2QEArBoOhWAhN3I1RCXn1i/TjF0CUYl68iQd3pUraf5eL2k5OTnAs6eQ1+oHWFjpd7K8HCReXoWcnBwGFipc/jCQYCGHYMnAQm8uhUJh7BKISkWpD+9bWEHQM7BI+dH2DCxERERSIADQNyRJeAolAwsREZEUCLLnm77nkCjpVk5ERERmgz0sREREUiAIBhgSku6YEAMLERGRFJj5kBADCxERkRSYeQ+LdKMWERERmQ32sBAREUmCAYaEJNxPwcBCREQkBRwSIiIiIjJt7GEhIiKSAjNfJSTdyomIiMxJ/pCQvpsOoqOj0aVLF7i5uUEQBGzbtq3AMXFxcejatSuUSiVsbW3RpEkT3L17V7M/KysLw4YNg5OTE8qVK4eePXsiKSlJ59tnYCEiIqJCZWZmol69eliyZEmh+2/cuIHmzZujRo0aOHToEC5cuICQkBCtN0GPHj0aO3bswKZNm3D48GHcv38fPXr00LkWDgkRERFJgRGGhDp06IAOHTq8dP+UKVPQsWNHzJkzR9NWpUoVzZ/T0tKwcuVKrF+/Hu+++y4AYNWqVfDx8cGJEyfwzjvvFLkW9rAQERFJgQGHhNLT07W27OxsnctRq9XYtWsXqlevjoCAADg7O6Np06Zaw0axsbHIzc2Fv7+/pq1GjRqoVKkSYmJidLoeAwsREZGZcXd3h1Kp1GwRERE6nyM5ORkZGRn46quv0L59e+zduxfvv/8+evTogcOHDwMAEhMTYWVlBXt7e63vuri4IDExUafrcUiIiIhICgw4JJSQkACFQqFplsvlOp9KrVYDALp164bRo0cDAOrXr4/jx49j+fLlaNWqlX61voCBhYiISAoEwQCB5fmQkEKh0AosxVG+fHlYWlqiZs2aWu0+Pj44evQoAEClUiEnJwepqalavSxJSUlQqVQ6XY9DQkRERKQzKysrNGnSBPHx8VrtV69ehYeHBwCgUaNGKFOmDA4cOKDZHx8fj7t378LX11en67GHhYiISApkwvNN33PoICMjA9evX9d8vnXrFs6dOwdHR0dUqlQJ48ePR+/evdGyZUu0adMGu3fvxo4dO3Do0CEAgFKpxIABAzBmzBg4OjpCoVBgxIgR8PX11WmFEMDAQkREJA1GWNZ8+vRptGnTRvN5zJgxAICgoCCsXr0a77//PpYvX46IiAiMHDkS3t7e2Lx5M5o3b675zoIFCyCTydCzZ09kZ2cjICAAS5cu1b10URRFnb9FOktPT4dSqYS8yWgIlrpPbiKSioeHZhm7BKISlZ6eDrcK9khLS9N7HkhRr6dUKiFvGQLB0vr1X3gF8VkWsqOnl1rthsQ5LERERGTyOCREREQkBWb+8kMGFiIiIikoxssLCz2HREk3ahEREZHZYA8LERGRFHBIiIiIiEweh4SIiIiITBt7WIiIiKSAQ0JERERk8jgkRERERGTa2MNCREQkCQYYEpJwPwUDCxERkRSY+ZAQAwsREZEUCIIBJt1KN7BIt2+IiIiIzAZ7WIiIiKSAy5qJiIjI5Jn5HBbpRi0iIiIyG+xhISIikgIOCREREZHJ45AQERERkWljDwsREZEUcEiIiIiITB6HhIiIiIhMG3tYiIiIJEAQBAhm3MPCwEJERCQB5h5YOCREREREJo89LERERFIg/G/T9xwSxcBCREQkAeY+JMTAQkREJAHmHlg4h4WIiIhMHntYiIiIJMDce1gYWIiIiCTA3AMLh4SIiIjI5LGHhYiISAq4rJmIiIhMHYeEiIiIiAoRHR2NLl26wM3NDYIgYNu2bS89dsiQIRAEAQsXLtRqT0lJQWBgIBQKBezt7TFgwABkZGToXAsDCxERkQQIwj+9LMXfdLtmZmYm6tWrhyVLlrzyuK1bt+LEiRNwc3MrsC8wMBCXL1/Gvn37sHPnTkRHR2Pw4MG6FQIOCREREUmCAAMMCek4iaVDhw7o0KHDK4+5d+8eRowYgT179qBTp05a++Li4rB7926cOnUKjRs3BgAsXrwYHTt2xNy5cwsNOC/DHhYiIiIzk56errVlZ2cX6zxqtRqffvopxo8fj1q1ahXYHxMTA3t7e01YAQB/f3/IZDKcPHlSp2sxsBAREUmA/sNB//TQuLu7Q6lUaraIiIhi1TR79mxYWlpi5MiRhe5PTEyEs7OzVpulpSUcHR2RmJio07U4JERERCQFBlzWnJCQAIVCoWmWy+U6nyo2NhaLFi3CmTNnDDBU9XrsYSEiIjIzCoVCaytOYDly5AiSk5NRqVIlWFpawtLSEnfu3MHYsWPh6ekJAFCpVEhOTtb63rNnz5CSkgKVSqXT9djDQkREJAUGeA6LaMCekE8//RT+/v5abQEBAfj000/Rr18/AICvry9SU1MRGxuLRo0aAQAOHjwItVqNpk2b6nQ9BhYiIiIJMMSD43T9fkZGBq5fv675fOvWLZw7dw6Ojo6oVKkSnJyctI4vU6YMVCoVvL29AQA+Pj5o3749Bg0ahOXLlyM3NxfDhw9Hnz59dFohBDCwEBERSYIxAsvp06fRpk0bzecxY8YAAIKCgrB69eoinWPdunUYPnw42rZtC5lMhp49eyIyMlKnOgAGFiIiInqJ1q1bQxTFIh9/+/btAm2Ojo5Yv3693rUwsBAREUkBX35IREREps4YQ0KmhMuaiYiIyOSxh4WIiEgCzL2HhYGFiIhIAsw9sHBIiIiIiEwee1iIiIgkwNx7WBhYiIiIpMDMlzVzSIiIiIhMHntYiIiIJIBDQkRERGTyGFiIiIjI5Jl7YOEcFpIUv/qe+GlOX9zcPhl/H49Al5Y1Cxzj7VEBm2Z/isS90/DwQBiOrhwGdxclAMDBzgbzR3fB+f+OQcpv4bi6ZSLmje4Cha28tG+FSC9PnjzBhLGj4FPNE+WVZdG2lR9iT58ydllEJYY9LCQpttZWuHj9AaJ2nsaPX31aYL/XW444sHwI1uw4hRkr9yM9Mxs1vVyQlfMMAOBaQQHX8gpM/uYXxN1ORiWVPRaPfx+u5e3w8RT93yZKVFqGDRmEK5cv4bv/i4Krqxs2/PcHdOnwHk6fuwy3t94ydnlUEsx8lRADC0nK3hNXsffE1ZfuD/usHfbExGPK0t2atlv3UjR/vnIzCR9NWae1L/TbPfi/ab1hYSFDXp66ZAonMqC///4b27duxo8/bUPzFi0BAFNCQvHrrp34bsUyTAubYeQKqSRwSIjoDSEIAtr71sC1uw/x84J+uLNrCqK/G1rosNG/KcpZIz0zi2GFJOPZs2fIy8uD3Npaq93GxgYxx48ZqSqiksXAQm8MZwdb2NnKMe7TVth34iq6jPo//Bx9GRtmBaJ5fa9Cv+OkLIvJ/d7F//3MsX+SDjs7OzR9xxezI2bgwf37yMvLw4b1P+DkiRgkPXhg7PKohOT3sOi7SRUDiw6Cg4PRvXt3zefWrVtj1KhRRquHtMlkz/9B3HnkChb/eAwXrj3A3LWH8cuxPzDo/aYFjrcrK8fWucGIu5WMGd/vL+1yifTy3f9FQRRFVPOqCEc7ayxbshgf9v4Igox/rb+pBBggsEh4EotRf7ODg4MhCAK++uorrfZt27bpnAI9PT2xcOHCIh334v+BFStW1OlaZJoepj5F7rM8xN1O1mqPv/OXZpVQvnJlrfDzgn548jQbvSf/gGccDiKJqVylCvbsP4SklCeIv3EXh4+dRG5uLry8Khu7NKISYfQobm1tjdmzZ+Px48elds3w8HA8ePBAs509e7bUrk0lJ/dZHmLj/kT1ShW02qu5l8fdxFTNZ7uycuxcOAA5uXn4YEIUsv+3gohIimxtbaFydcXjx49xYN8edOrS1dglUQnhkJCR+fv7Q6VSISIi4pXHbd68GbVq1YJcLoenpyfmzZun2de6dWvcuXMHo0ePLtL/IXZ2dlCpVJqtQoUKyMvLw4ABA+Dl5QUbGxt4e3tj0aJFBrlHMhxbGyvUreaKutVcAQCerg6oW81V04OyYF00PmhbB/26NkHlt5wwpKcvOvrVwIotJwDkh5X+KGtdBkMiNkNhK4eLYzm4OJbTDCkRScH+vXuwb89u3L51Cwf370PHdu+iuncNfBrUz9ilUUkRDLRJlNGXNVtYWGDWrFn4+OOPMXLkyEKHZ2JjY9GrVy+Ehoaid+/eOH78OIYOHQonJycEBwdjy5YtqFevHgYPHoxBgwYVqw61Wo2KFSti06ZNcHJywvHjxzF48GC4urqiV69eOp8vOzsb2dnZms/p6enFqou0NazxFvYuGaz5POfzzgCAtbtiMXjmT/g5+gpGzNmG8X1bY97oLrh65y98NGUdjl+4AwCo7+2Gt2tXAgBc2TRe69zePWZr9cQQmbK09DSEfvkF7t37Ew6OjujWvQemhc9EmTJljF0aUYkwemABgPfffx/169fHtGnTsHLlygL758+fj7Zt2yIkJAQAUL16dVy5cgVff/01goOD4ejoCAsLC03PyetMnDgRX375pebzrFmzMHLkSISFhWnavLy8EBMTg40bNxYrsERERGidjwzjyNlbsGk2+ZXHRO2KRdSu2GJ/n0gKen7QCz0/0P3vJpIuPofFRMyePRtr1qxBXFxcgX1xcXHw8/PTavPz88O1a9eQl5en87XGjx+Pc+fOaba+ffsCAJYsWYJGjRqhQoUKKFeuHFasWIG7d+8W634mT56MtLQ0zZaQkFCs8xAREQGcw2ISPSwA0LJlSwQEBGDy5MkIDg4u0WuVL18eVatW1WrbsGEDxo0bh3nz5sHX1xd2dnb4+uuvcfLkyWJdQy6XQy7n+2mIiIgMwWQCCwB89dVXqF+/Pry9vbXafXx8cOyY9tMbjx07hurVq8PCwgIAYGVlVazeln+fr1mzZhg6dKim7caNG8U+HxERkSEJwvNN33NIlckMCQFAnTp1EBgYiMjISK32sWPH4sCBA5g+fTquXr2KNWvW4JtvvsG4ceM0x3h6eiI6Ohr37t3Dw4cPdb52tWrVcPr0aezZswdXr15FSEgITp3i00+JiMg0PA8s+g4JGfsuis+kAgvw/BkparX2Q7waNmyIjRs3YsOGDahduzamTp2K8PBwraGj8PBw3L59G1WqVEGFChWgq88++ww9evRA79690bRpUzx69Eirt4WIiMiohH96WYq7SXlZsyCKomjsIsxBeno6lEol5E1GQ7Dk3BZ6cz08NMvYJRCVqPT0dLhVsEdaWhoUCkWpXE+pVKLyyJ9gIbfV61x52Zm4GflBqdVuSCY1h4WIiIgKZ+7LmhlYiIiIJICTbomIiIhMHHtYiIiIJEAmE/R+55ko4XemMbAQERFJAIeEiIiIiEwce1iIiIgkwNxXCbGHhYiISAL0fWhccYaUoqOj0aVLF7i5uUEQBGzbtk2zLzc3FxMnTkSdOnVga2sLNzc39O3bF/fv39c6R0pKCgIDA6FQKGBvb48BAwYgIyND5/tnYCEiIqJCZWZmol69eliyZEmBfU+fPsWZM2cQEhKCM2fOYMuWLYiPj0fXrl21jgsMDMTly5exb98+7Ny5E9HR0Rg8eLDOtXBIiIiISAIMOSSUnp6u1S6XyyGXF3wKe4cOHdChQ4dCz6VUKrFv3z6ttm+++QZvv/027t69i0qVKiEuLg67d+/GqVOn0LhxYwDA4sWL0bFjR8ydOxdubm5Frp09LERERBKg/4sP/wk87u7uUCqVmi0iIsIgNaalpUEQBNjb2wMAYmJiYG9vrwkrAODv7w+ZTIaTJ0/qdG72sBAREUmAIZc1JyQkaL1LqLDeFV1lZWVh4sSJ+OijjzTnTkxMhLOzs9ZxlpaWcHR0RGJiok7nZ2AhIiIyMwqFwqAvP8zNzUWvXr0giiKWLVtmsPP+GwMLERGRBAgwwBwWGH5Zc35YuXPnDg4ePKgVhFQqFZKTk7WOf/bsGVJSUqBSqXS6DuewEBERSYAxljW/Tn5YuXbtGvbv3w8nJyet/b6+vkhNTUVsbKym7eDBg1Cr1WjatKlO12IPCxERERUqIyMD169f13y+desWzp07B0dHR7i6uuKDDz7AmTNnsHPnTuTl5WnmpTg6OsLKygo+Pj5o3749Bg0ahOXLlyM3NxfDhw9Hnz59dFohBDCwEBERSYIxnnR7+vRptGnTRvN5zJgxAICgoCCEhobi559/BgDUr19f63u//fYbWrduDQBYt24dhg8fjrZt20Imk6Fnz56IjIzUuXYGFiIiIgkwxssPW7duDVEUX7r/VfvyOTo6Yv369bpduBCcw0JEREQmjz0sREREEmDuLz9kYCEiIpIAYwwJmRIOCREREZHJYw8LERGRBHBIiIiIiEyfIR78Jt28wiEhIiIiMn3sYSEiIpIADgkRERGRyTP3VUIMLERERBJg7j0snMNCREREJo89LERERBLAISEiIiIyeRwSIiIiIjJx7GEhIiKSAHPvYWFgISIikgBzn8PCISEiIiIyeexhISIikgAOCREREZHJ45AQERERkYljDwsREZEEcEiIiIiITJ4AAwwJGaQS42BgISIikgCZIECmZ2LR9/vGxDksREREZPLYw0JERCQB5r5KiIGFiIhIAsx90i2HhIiIiMjksYeFiIhIAmTC803fc0gVAwsREZEUCAYY0pFwYOGQEBEREZk89rAQERFJAFcJERERkckT/vc/fc8hVRwSIiIiIpPHHhYiIiIJ4CohIiIiMnl8cBwRERFRIaKjo9GlSxe4ublBEARs27ZNa78oipg6dSpcXV1hY2MDf39/XLt2TeuYlJQUBAYGQqFQwN7eHgMGDEBGRobOtRSph+Xnn38u8gm7du2qcxFERET0asZYJZSZmYl69eqhf//+6NGjR4H9c+bMQWRkJNasWQMvLy+EhIQgICAAV65cgbW1NQAgMDAQDx48wL59+5Cbm4t+/fph8ODBWL9+vU61FCmwdO/evUgnEwQBeXl5OhVARERErycTBMj0TCy6fr9Dhw7o0KFDoftEUcTChQvx5Zdfolu3bgCAqKgouLi4YNu2bejTpw/i4uKwe/dunDp1Co0bNwYALF68GB07dsTcuXPh5uZW9NqLcpBarS7SxrBCRERUMvJ7WPTdACA9PV1ry87O1rmeW7duITExEf7+/po2pVKJpk2bIiYmBgAQExMDe3t7TVgBAH9/f8hkMpw8eVKn6+k1hyUrK0ufrxMREZERuLu7Q6lUaraIiAidz5GYmAgAcHFx0Wp3cXHR7EtMTISzs7PWfktLSzg6OmqOKSqdVwnl5eVh1qxZWL58OZKSknD16lVUrlwZISEh8PT0xIABA3Q9JREREb2GIVcJJSQkQKFQaNrlcrle5y0NOvewzJw5E6tXr8acOXNgZWWlaa9duza+//57gxZHREREzxlySEihUGhtxQksKpUKAJCUlKTVnpSUpNmnUqmQnJystf/Zs2dISUnRHFNUOgeWqKgorFixAoGBgbCwsNC016tXD3/88YeupyMiIiIJ8vLygkqlwoEDBzRt6enpOHnyJHx9fQEAvr6+SE1NRWxsrOaYgwcPQq1Wo2nTpjpdT+choXv37qFq1aoF2tVqNXJzc3U9HRERERWBMVYJZWRk4Pr165rPt27dwrlz5+Do6IhKlSph1KhRmDFjBqpVq6ZZ1uzm5qZZXezj44P27dtj0KBBWL58OXJzczF8+HD06dNHpxVCQDECS82aNXHkyBF4eHhotf/0009o0KCBrqcjIiKiIhD+t+l7Dl2cPn0abdq00XweM2YMACAoKAirV6/GhAkTkJmZicGDByM1NRXNmzfH7t27Nc9gAYB169Zh+PDhaNu2LWQyGXr27InIyEida9c5sEydOhVBQUG4d+8e1Go1tmzZgvj4eERFRWHnzp06F0BERESmqXXr1hBF8aX7BUFAeHg4wsPDX3qMo6Ojzg+JK4zOc1i6deuGHTt2YP/+/bC1tcXUqVMRFxeHHTt24L333tO7ICIiIioof5WQvptUFevlhy1atMC+ffsMXQsRERG9BN/WXEynT59GXFwcgOfzWho1amSwooiIiIj+TefA8ueff+Kjjz7CsWPHYG9vDwBITU1Fs2bNsGHDBlSsWNHQNRIREZk9Qz44Top0nsMycOBA5ObmIi4uDikpKUhJSUFcXBzUajUGDhxYEjUSERERDPPQOKnSuYfl8OHDOH78OLy9vTVt3t7eWLx4MVq0aGHQ4oiIiIiAYgQWd3f3Qh8Ql5eXp/NDYIiIiKhoOCSko6+//hojRozA6dOnNW2nT5/G559/jrlz5xq0OCIiInouf5WQvptUFamHxcHBQSuVZWZmomnTprC0fP71Z8+ewdLSEv3799c8jpeIiIgMx9x7WIoUWBYuXFjCZRARERG9XJECS1BQUEnXQURERK9gjHcJmZJiPzgOALKyspCTk6PVplAo9CqIiIiICjLG25pNic6TbjMzMzF8+HA4OzvD1tYWDg4OWhsRERGRoekcWCZMmICDBw9i2bJlkMvl+P777xEWFgY3NzdERUWVRI1ERERmT9+Hxkn94XE6Dwnt2LEDUVFRaN26Nfr164cWLVqgatWq8PDwwLp16xAYGFgSdRIREZk1c18lpHMPS0pKCipXrgzg+XyVlJQUAEDz5s0RHR1t2OqIiIiIUIzAUrlyZdy6dQsAUKNGDWzcuBHA856X/JchEhERkWGZ+5CQzoGlX79+OH/+PABg0qRJWLJkCaytrTF69GiMHz/e4AUSERHRP6uE9N2kSuc5LKNHj9b82d/fH3/88QdiY2NRtWpV1K1b16DFEREREQF6PocFADw8PODh4WGIWoiIiOglDDGkI+EOlqIFlsjIyCKfcOTIkcUuhoiIiApn7quEihRYFixYUKSTCYLAwPIad3eH8mnA9EZzaDLc2CUQlSgxL+f1B5UAGYox8bSQc0hVkQJL/qogIiIiImPQew4LERERlTwOCREREZHJEwRAZsaTbqU8nEVERERmgj0sREREEiAzQA+Lvt83JgYWIiIiCTD3OSzFGhI6cuQIPvnkE/j6+uLevXsAgLVr1+Lo0aMGLY6IiIgIKEZg2bx5MwICAmBjY4OzZ88iOzsbAJCWloZZs2YZvEAiIiL6Z0hI302qdA4sM2bMwPLly/Hdd9+hTJkymnY/Pz+cOXPGoMURERHRc3xbs47i4+PRsmXLAu1KpRKpqamGqImIiIhIi86BRaVS4fr16wXajx49isqVKxukKCIiItImEwSDbFKlc2AZNGgQPv/8c5w8eRKCIOD+/ftYt24dxo0bh//85z8lUSMREZHZkxlokyqdlzVPmjQJarUabdu2xdOnT9GyZUvI5XKMGzcOI0aMKIkaiYiIyMzpHLYEQcCUKVOQkpKCS5cu4cSJE/jrr78wffr0kqiPiIiIYJxJt3l5eQgJCYGXlxdsbGxQpUoVTJ8+HaIoao4RRRFTp06Fq6srbGxs4O/vj2vXrhn47vV4cJyVlRVq1qxpyFqIiIjoJWTQfw6KDLp9f/bs2Vi2bBnWrFmDWrVq4fTp0+jXrx+USiVGjhwJAJgzZw4iIyOxZs0aeHl5ISQkBAEBAbhy5Qqsra31qvffdA4sbdq0eeWT8g4ePKhXQURERFSQIZYl6/r948ePo1u3bujUqRMAwNPTE//973/x+++/A3jeu7Jw4UJ8+eWX6NatGwAgKioKLi4u2LZtG/r06aNfwf+i85BQ/fr1Ua9ePc1Ws2ZN5OTk4MyZM6hTp47BCiMiIqKSkZ6errXlPwT2Rc2aNcOBAwdw9epVAMD58+dx9OhRdOjQAQBw69YtJCYmwt/fX/MdpVKJpk2bIiYmxqA169zDsmDBgkLbQ0NDkZGRoXdBREREVJAhX37o7u6u1T5t2jSEhoYWOH7SpElIT09HjRo1YGFhgby8PMycOROBgYEAgMTERACAi4uL1vdcXFw0+wzFYC8//OSTT/D2229j7ty5hjolERER/Y8gQO85LPlfT0hIgEKh0LTL5fJCj9+4cSPWrVuH9evXo1atWjh37hxGjRoFNzc3BAUF6VWLrgwWWGJiYgw6uYaIiIhKhkKh0AosLzN+/HhMmjRJMxelTp06uHPnDiIiIhAUFASVSgUASEpKgqurq+Z7SUlJqF+/vkFr1jmw9OjRQ+uzKIp48OABTp8+jZCQEIMVRkRERP8wxqTbp0+fQibTnu5qYWEBtVoNAPDy8oJKpcKBAwc0ASU9PR0nT540+MNkdQ4sSqVS67NMJoO3tzfCw8PRrl07gxVGRERE/zDkHJai6tKlC2bOnIlKlSqhVq1aOHv2LObPn4/+/fsDeP5stlGjRmHGjBmoVq2aZlmzm5sbunfvrl+xL9ApsOTl5aFfv36oU6cOHBwcDFoIERERmZbFixcjJCQEQ4cORXJyMtzc3PDZZ59h6tSpmmMmTJiAzMxMDB48GKmpqWjevDl2795t8Gkigvjvx9UVgbW1NeLi4uDl5WXQQt506enpUCqVSHqUVqRxQyKpcmgy3NglEJUoMS8H2Re/Q1pa6fx9nv/vj5DtZ2Fta6fXubIyn2B6twalVrsh6fwcltq1a+PmzZslUQsRERG9RP6QkL6bVOkcWGbMmIFx48Zh586dePDgQYGHzxAREREZWpHnsISHh2Ps2LHo2LEjAKBr165aj+gXRRGCICAvL8/wVRIREZk5Y0y6NSVFDixhYWEYMmQIfvvtt5Ksh4iIiAohCMIr3+VX1HNIVZEDS/7c3FatWpVYMURERFQ4c+9h0WkOi5STGREREUmXTs9hqV69+mtDS0pKil4FERERUUHGeNKtKdEpsISFhRV40i0RERGVPJkg6P3yQ32/b0w6BZY+ffrA2dm5pGohIiIiKlSRAwvnrxARERmPuU+61XmVEBERERmBAeawwBwCS/6rpImIiIhKm05zWIiIiMg4ZBAg07OLRN/vGxMDCxERkQSY+7JmnV9+SERERFTa2MNCREQkAVwlRERERCbP3B8cxyEhIiIiMnnsYSEiIpIAc590y8BCREQkATIYYEiIy5qJiIioJJl7DwvnsBAREZHJYw8LERGRBMigfy+DlHspGFiIiIgkQBAECHqO6ej7fWOSctgiIiIiM8EeFiIiIgkQ/rfpew6pYmAhIiKSAD7ploiIiMjEsYeFiIhIIqTbP6I/BhYiIiIJ4IPjiIiIiEwce1iIiIgkwNyfw8LAQkREJAF80i0RERGZPHPvYZFy2CIiIiIzwcBCREQkAYKBNl3du3cPn3zyCZycnGBjY4M6derg9OnTmv2iKGLq1KlwdXWFjY0N/P39ce3atWLf58swsBAREUlA/pCQvpsuHj9+DD8/P5QpUwa//vorrly5gnnz5sHBwUFzzJw5cxAZGYnly5fj5MmTsLW1RUBAALKysgx6/5zDQkRERIWaPXs23N3dsWrVKk2bl5eX5s+iKGLhwoX48ssv0a1bNwBAVFQUXFxcsG3bNvTp08dgtbCHhYiISAJkBtoAID09XWvLzs4u9Jo///wzGjdujA8//BDOzs5o0KABvvvuO83+W7duITExEf7+/po2pVKJpk2bIiYmxoB3z8BCREQkCYYcEnJ3d4dSqdRsERERhV7z5s2bWLZsGapVq4Y9e/bgP//5D0aOHIk1a9YAABITEwEALi4uWt9zcXHR7DMUDgkRERGZmYSEBCgUCs1nuVxe6HFqtRqNGzfGrFmzAAANGjTApUuXsHz5cgQFBZVKrfnYw0JERCQBhlwlpFAotLaXBRZXV1fUrFlTq83Hxwd3794FAKhUKgBAUlKS1jFJSUmafYbCwEJERCQB+S8/1HfThZ+fH+Lj47Xarl69Cg8PDwDPJ+CqVCocOHBAsz89PR0nT56Er6+v3vf8bxwSIiIiokKNHj0azZo1w6xZs9CrVy/8/vvvWLFiBVasWAHg+byaUaNGYcaMGahWrRq8vLwQEhICNzc3dO/e3aC1MLAQERFJgAwCZMV69Jv2OXTRpEkTbN26FZMnT0Z4eDi8vLywcOFCBAYGao6ZMGECMjMzMXjwYKSmpqJ58+bYvXs3rK2t9ar1RQwsREREElCcIZ3CzqGrzp07o3Pnzq84p4Dw8HCEh4frUdnrcQ4LERERmTz2sBAREUmA8L//6XsOqWJgISIikgBjDQmZCgYWIiIiCRAMMOlWyj0snMNCREREJo89LERERBLAISEiIiIyeeYeWDgkRERERCaPPSxEREQSwGXNREREZPJkwvNN33NIFYeEiIiIyOSxh4WIiEgCOCREREREJo+rhIjeMN5VPWFTRiiwjRoxzNilERWJX8Mq+GnhZ7i5dyb+PvsNurSuW+AYby8XbFr4GRKjv8bD4/Nw9IfxcFc5aPa7ONlh5fS+uLVvFh4en4fj6yeie9v6pXgXRIbFHhZ64xyNOYW8vDzN5yuXL6FT+/fQ44MPjVgVUdHZ2shx8eo9RG2PwY/zBxfY71WxPA783xis2XYcM5btQnpmFmpWcUVWdq7mmO+n94W9nQ0+HPUtHqZmoHeHxvhhdn/4Bc7B+fg/S/N2yEAE6D+kI+EOFgYWevNUqFBB6/PcOV+hcpUqaNGylZEqItLN3mNXsPfYlZfuDxveBXuOXsaURds1bbf+fKh1zDv1KmPkrA04ffkOAGD293swIvBdNKjpzsAiUVwlRPQGy8nJwYb1PyAouD8EKQ/eEv2PIAho37wWrt1Nxs9LhuHOgQhER40rMGx04vxNfNCuERwUZSEIAj4MaARruSWiT18zUuWkL8FA/5MqBpYiWr16Nezt7TWfQ0NDUb9+faPVQ0Xz8/ZtSE1NxSd9g41dCpFBODuWg52tNcb1ew/7jl9Bl/98g59/O48N8waieaOqmuM+mfB/KGNpgfuH5yDt5EIsntIHvcd8h5sJD19xdiLTZXaBJTg4GIIgFNiuX79u7NKoBKxZtRIB7TvAzc3N2KUQGYRM9vyv7Z2HLmLxut9w4eo9zF21D78cuYxBHzTXHDdtWGfY29mgw2eR8PtkDiJ/OIgf5vRHrar8Z0Gq8lcJ6btJlVnOYWnfvj1WrVql1fbivAeSvjt37uDggf3YsGmLsUshMpiHjzOQm5uHuJsPtNrjbyaiWYPKAJ5Pyv1Pn1Zo2HMG4m4mAgAuXr0Hv4ZV8Fnvlhg5c0Op1036E6D/pFkJ5xXz62EBALlcDpVKpbUtWrQIderUga2tLdzd3TF06FBkZGQYu1TSw9o1q+Ds7IwOHTsZuxQig8l9lofYK3dQ3cNFq72ahzPuPngMAChrbQUAUIui1jF5eSJkUv5PbDJrZhlYCiOTyRAZGYnLly9jzZo1OHjwICZMmFDs82VnZyM9PV1ro9KjVqsRtWYVAj8NgqWlWXYkkoTZ2lihbvW3ULf6WwAAz7ecULf6W5rnrCxYsx8fBDREv/ebobJ7eQzp3RIdW9bGio3RAID424m4fjcZ33z5ERrX8oBXxfL4/NN30fYdb+w4dN5o90X6kUGATNBzk3Afi1n+Tb5z506UK1dO87lDhw7YtGmT5rOnpydmzJiBIUOGYOnSpcW6RkREBMLCwvSulYrn4IH9SLh7F0HB/Y1dCpHOGtb0wN7vP9d8njOuJwBg7c8nMHjaD/j5twsYMXMDxvdvh3kTPsDVO8n4aPz3OH7uJgDg2TM1uo9Yhhkju+GnRZ+hXFk5biT8hYFT12LP0ZcvlybTZu5DQmYZWNq0aYNly5ZpPtva2mL//v2IiIjAH3/8gfT0dDx79gxZWVl4+vQpypYtq/M1Jk+ejDFjxmg+p6enw93d3SD10+v5v9cOf+eKrz+QyAQdib0GmwbDX3lM1PYTiNp+4qX7b9z9Cx+N+97QpREZjVkOCdna2qJq1aqaLTs7G507d0bdunWxefNmxMbGYsmSJQCeP8ejOORyORQKhdZGRERUbIKBNokyyx6WF8XGxkKtVmPevHmaJYMbN240clVERET/MPe3NZtlD8uLqlatitzcXCxevBg3b97E2rVrsXz5cmOXRURERP/DwAKgXr16mD9/PmbPno3atWtj3bp1iIiIMHZZRERE/zDEQ+Ok28ECQRRFzkwsBenp6VAqlUh6lMb5LPRGc2jy6smiRFIn5uUg++J3SEsrnb/P8//9cfDcXZSz0+96GU/S8W79SqVWuyGxh4WIiIhMHifdEhERSYGZP4iFgYWIiEgCzH2VEAMLERGRBBjibctSfpUU57AQERGRyWMPCxERkQSY+RQW9rAQERFJgpEfzf/VV19BEASMGjVK05aVlYVhw4bByckJ5cqVQ8+ePZGUlFT8i7wCAwsRERG90qlTp/Dtt9+ibt26Wu2jR4/Gjh07sGnTJhw+fBj3799Hjx49SqQGBhYiIiIJEAz0P11lZGQgMDAQ3333HRwcHDTtaWlpWLlyJebPn493330XjRo1wqpVq3D8+HGcOPHyN4kXFwMLERGRBOj7WP5/rzJKT0/X2rKzs1963WHDhqFTp07w9/fXao+NjUVubq5We40aNVCpUiXExMQY/P4ZWIiIiMyMu7s7lEqlZnvZ+/M2bNiAM2fOFLo/MTERVlZWsLe312p3cXFBYmKiwWvmKiEiIiIJMOQqoYSEBK13Ccnl8gLHJiQk4PPPP8e+fftgbW2t55X1xx4WIiIiKTDgKiGFQqG1FRZYYmNjkZycjIYNG8LS0hKWlpY4fPgwIiMjYWlpCRcXF+Tk5CA1NVXre0lJSVCpVAa/ffawEBERUQFt27bFxYsXtdr69euHGjVqYOLEiXB3d0eZMmVw4MAB9OzZEwAQHx+Pu3fvwtfX1+D1MLAQERFJQGm/S8jOzg61a9fWarO1tYWTk5OmfcCAARgzZgwcHR2hUCgwYsQI+Pr64p133tGrzsIwsBAREUmAKb5LaMGCBZDJZOjZsyeys7MREBCApUuXGvYi/8PAQkREREVy6NAhrc/W1tZYsmQJlixZUuLXZmAhIiKSAHN/lxADCxERkRSYeWJhYCEiIpKA0p50a2r4HBYiIiIyeexhISIikgBTXCVUmhhYiIiIJMDMp7BwSIiIiIhMH3tYiIiIpMDMu1gYWIiIiCSAq4SIiIiITBx7WIiIiCSAq4SIiIjI5Jn5FBYOCREREZHpYw8LERGRFJh5FwsDCxERkQSY+yohBhYiIiIpMMCkWwnnFc5hISIiItPHHhYiIiIJMPMpLAwsREREkmDmiYVDQkRERGTy2MNCREQkAVwlRERERCbP3B/NzyEhIiIiMnnsYSEiIpIAM59zy8BCREQkCWaeWDgkRERERCaPPSxEREQSwFVCREREZPIEGGCVkEEqMQ4OCREREZHJYw8LERGRBJj5nFsGFiIiIikw9wfHMbAQERFJgnn3sXAOCxEREZk89rAQERFJAIeEiIiIyOSZ94AQh4SIiIjoJSIiItCkSRPY2dnB2dkZ3bt3R3x8vNYxWVlZGDZsGJycnFCuXDn07NkTSUlJBq+FgYWIiEgC8oeE9N10cfjwYQwbNgwnTpzAvn37kJubi3bt2iEzM1NzzOjRo7Fjxw5s2rQJhw8fxv3799GjRw8D3z2HhIiIiCTBGI/m3717t9bn1atXw9nZGbGxsWjZsiXS0tKwcuVKrF+/Hu+++y4AYNWqVfDx8cGJEyfwzjvv6FXvv7GHhYiIyMykp6drbdnZ2UX6XlpaGgDA0dERABAbG4vc3Fz4+/trjqlRowYqVaqEmJgYg9bMwEJERCQFgoE2AO7u7lAqlZotIiLitZdXq9UYNWoU/Pz8ULt2bQBAYmIirKysYG9vr3Wsi4sLEhMT9bxhbRwSIiIikgBDrhJKSEiAQqHQtMvl8td+d9iwYbh06RKOHj2qZxXFw8BCRERkZhQKhVZgeZ3hw4dj586diI6ORsWKFTXtKpUKOTk5SE1N1eplSUpKgkqlMmTJHBIiIiKSAmOsEhJFEcOHD8fWrVtx8OBBeHl5ae1v1KgRypQpgwMHDmja4uPjcffuXfj6+hritjXYw0JERCQBxlglNGzYMKxfvx7bt2+HnZ2dZl6KUqmEjY0NlEolBgwYgDFjxsDR0REKhQIjRoyAr6+vQVcIAQwsRERE0mCER90uW7YMANC6dWut9lWrViE4OBgAsGDBAshkMvTs2RPZ2dkICAjA0qVL9Sy0IAYWIiIiKpQoiq89xtraGkuWLMGSJUtKtBYGFiIiIgkw93cJMbAQERFJgLm/rZmrhIiIiMjksYeFiIhIEvRfJSTlQSEGFiIiIgngkBARERGRiWNgISIiIpPHISEiIiIJ4JAQERERkYljDwsREZEEGONdQqaEgYWIiEgCOCREREREZOLYw0JERCQBfJcQERERmT4zTywMLERERBJg7pNuOYeFiIiITB57WIiIiCTA3FcJMbAQERFJgJlPYeGQEBEREZk+9rAQERFJgZl3sTCwEBERSQBXCRERERGZOPawlBJRFAEAT9LTjVwJUckS83KMXQJRicr/Hc//e720PHmSrvcqnydPpPvvIAaWUvLkyRMAQFUvdyNXQkREhvDkyRMolcoSv46VlRVUKhWqGejfHyqVClZWVgY5V2kSxNKOiGZKrVbj/v37sLOzgyDlhfASkp6eDnd3dyQkJEChUBi7HKISwd/z0ieKIp48eQI3NzfIZKUzsyIrKws5OYbpvbSysoK1tbVBzlWa2MNSSmQyGSpWrGjsMsySQqHgX+T0xuPveekqjZ6Vf7O2tpZkyDAkTrolIiIik8fAQkRERCaPgYXeWHK5HNOmTYNcLjd2KUQlhr/nZC446ZaIiIhMHntYiIiIyOQxsBAREZHJY2AhIiIik8fAQkRERCaPgYXof65fv27sEoiI6CUYWIgArFu3DkFBQdixY4exSyHSi1qtNnYJRCWCgYUIgJeXFywsLLBixQrs3LnT2OUQ6eyXX34B8Pw1IAwt9CZiYCGztnv3bqSkpKBZs2aYN28eMjMzsXTpUoYWkpTTp09jyJAh6N+/PwCGFnozMbCQ2YqJicHo0aMxefJkpKamokmTJvjqq6+QlZXF0EKSUrlyZYwZMwbnz5/HwIEDATC00JuHgYXMVpMmTfDJJ5/gypUr+OKLL/D48WO8/fbbDC0kGYsWLcLRo0fh6OiI4OBgBAUF4fTp0wwt9EZiYCGzpFarYWlpiYkTJ6JTp044e/YspkyZwtBCkvHw4UP8+uuv6Nq1K37//XfY29ujb9++6N+/P0MLvZEYWMgsyWQy5OXlwdLSEuPGjUPXrl0LhJbZs2cjKysLK1aswJYtW4xdMpGW8uXLY968eQgICECXLl1w8uRJhhZ6ozGwkNmysLAAAFhaWmL8+PHo0qWLVmhp0qQJ5syZgz///BMbNmxARkaGkSsmei7/nbW1atVCSEgIWrVqha5duzK00BuNb2smsyKKIgRBwKVLlxAfHw+lUgkPDw9Uq1YNubm5mDNnDnbu3IkGDRpg1qxZsLe3x5kzZ+Dk5AQPDw9jl0+koVarIZM9/2/OS5cuITw8HIcPH8bPP/+Mpk2bIjU1FVFRUYiKikKVKlXw448/GrliIv0wsNAbLz+kPHv2DJaWltiyZQtGjBgBJycnqNVquLm5YeLEiWjbtq0mtOzevRuenp745ptvoFQqjX0LRBr5v88vunDhAmbMmFEgtHz77bfYtWsXfvzxR7i6uhqhYiLDYGChN1b+f4GmpqbC3t4eAPDbb7+hV69eCAsLw9ChQ7Fp0yb0798f7u7u+Prrr9GpUyfk5uYiNDQUp06dQlRUFFQqlXFvhOh/8sPK0aNHNU9l9vHxQXBwMADg4sWLmD59Og4fPowdO3bg7bffRlpaGtRqNRwcHIxYOZH+GFjojZQfVs6dO4d3330XBw4cQI0aNTBy5Eg4ODhgzpw5uHfvHpo3b4569eohLy8P165dw9KlS/Huu+/i2bNnSEtLg5OTk7FvhcxY/u9xZmYmbG1tAQBbtmzBoEGD0LJlS9jZ2WH79u0YPXo0QkNDATwPLREREdi4cSNOnjyJRo0aGfEOiAxIJHrD5OXliaIoiufOnRNtbW3FSZMmafZduHBBPHLkiPj48WOxQYMG4sCBA0VRFMUff/xRtLS0FF1cXMRdu3YZpW6if8v/PT59+rRYpUoV8a+//hJPnToluru7i8uWLRNFURSvXr0qKpVKURAEccSIEZrvnjlzRgwODhbj4+ONUjtRSbA0dmAiMqT8/yK9ePEifH19MW7cOISHh2v2V65cGba2tti5cyfkcjmmTZsGAHBzc0PLli1Rr1491KhRw1jlEwH45/f4/PnzaNOmDfr374/y5ctjx44d6NWrF4YMGYKEhAS0a9cOvXr1QpMmTfDZZ5/BwcEBYWFhaNCgAb799ltYWVkZ+1aIDIaBhd4oMpkMd+7cga+vL7p166YVVubPn4/09HSEhobi6dOnuHLlCu7fv4+KFSvil19+QeXKlTFt2jROsiWjyg8rFy5cQLNmzTBq1CjMnDkTANCvXz8cPnxY8+c2bdpgxYoV+PPPP+Hm5obp06fj6dOn+PrrrxlW6I3DwEJvHFEU4eDggOzsbBw5cgQtWrTA3LlzERISgl27dgF4PlGxefPm+PDDD+Hp6YnY2FjExMQwrJDRyWQyJCQkoG3btujcubMmrADAsmXLcPv2bVSsWBGPHj1CWFgYAKBs2bJ477334O/vj8aNGxurdKISxQfH0RtFrVbD09MT+/fvx9WrV7Fw4UIMGTIEERER+OWXX/Duu+8CAOrUqYMJEyZgxIgRaNKkCU6fPo06deoYuXqi5/Ly8uDl5YWsrCwcO3YMABAREYFJkyahU6dOsLa2xuXLl3H8+HE8ffoUc+fOxcWLF9GhQwd4e3sbuXqiksFVQvTGye9S/+OPP9C7d29cvHgRc+fOxZgxYwBA8zwWIlN27do1jBw5ElZWVnBxccH27duxdu1atGvXDgAwd+5cTJgwAVWrVkVKSgr27duHBg0aGLlqopLDwEJvpPzQcuPGDXTv3h2enp6YMGECWrRoobUfePmDuIiM7erVqxg+fDiOHj2K6dOnY+zYsZp9OTk5uHTpEhISEtCwYUO4u7sbsVKiksfAQpKX/36U/Hel5AeRf/e0fPDBB/Dw8MDkyZPRvHlzY5ZLpJMbN25g6NChsLCwwBdffKH5/f337zqROeBvO0lOfkDJysoC8DyoXLt2TfPnfPkBpkaNGvjpp59w7949TJo0CTExMaVfNFExValSBd988w1EUcSMGTM0c1oYVsjc8DeeJEcmk+HmzZsYNWoU7t27h59++gk+Pj64fPlyocfmh5Z169ZBrVajYsWKRqiaqPiqVauGyMhIlClTBuPGjcOJEyeMXRJRqeOQEElSdHQ0unfvjnr16iEmJgYrVqxA3759XzofJS8vDxYWFsjNzUWZMmWMUDGR/v744w+EhIRg3rx5qFSpkrHLISpVDCwkOfmhZPbs2Zg8eTLeeecdREVFoWrVqlr7X/VdIqnKycnhQ+HILHFIiCQnLy8PAGBtbY2pU6ciKSkJoaGhOHv2LABAEAT8O4fnz3nJ30ckZQwrZK7Yw0KSkd878uJzVPbu3YvPPvsMzZo1w4QJE1CvXj0AQExMDHx9fY1VLhERGRADC0lCflg5cOAAtm7disePH6NmzZoYNGgQnJ2dsXfvXgwZMgR+fn7o06cPzpw5g2nTpiExMREVKlRgzwoRkcQxsJBkbNu2DR999BE++eQT3LlzB48fP8Zff/2F6OhoVKpUCQcOHMC4ceOgVquRnp6On376CY0aNTJ22UREZAAMLGSSXpwc+/DhQ7z33nv4+OOPMX78eADApUuXMHbsWFy7dg2///47ypcvj9u3byM9PR0VKlSAq6ursconIiID46RbMin5+fnp06cA/pkwm5GRgQcPHqB+/fqaY318fDBnzhw4ODhgw4YNAABPT0/UrVuXYYWI6A3DwEImRRAEJCcnw9PTExs3btQ8zVOlUsHd3R2HDx/WHGthYYG6devC0tIS8fHxxiqZiIhKAQMLmRyZTIauXbvi008/xfbt2zVtTZs2xcGDB7FlyxbNsYIg4K233oK9vT1EUQRHOImI3kycw0JGV9jD3JKTkzFz5kwsXrwYmzdvxvvvv49Hjx4hMDAQaWlpaNq0Kfz8/BAdHY2oqCicPHkSNWrUMNIdEBFRSWNgIaPKf+NsZmYm8vLyoFAoNPsePHiAWbNmYcmSJdi0aRN69uyJR48e4auvvsKxY8fw8OFDqFQqREZGas1tISKiNw8DCxndtWvX0KtXL5QrVw6DBg2CSqVCu3btAADZ2dkYO3Ysli5dih9//BEffvghnj17BkEQkJKSgrJly8LW1tbId0BERCXN8vWHEJUctVqN1atX4/z587C2tkZqaiqePn0KR0dHvP322+jfvz/69esHJycn9O7dGwqFAgEBAQCAChUqGLl6IiIqLexhIaNLTEzE7NmzcePGDVStWhXDhg3DunXrcOTIEVy4cAGOjo6oXLkyYmNjkZycjEOHDqFly5bGLpuIiEoRe1jI6FQqFcaPH49Zs2bh6NGjqFatGqZOnQoAOHnyJO7fv48VK1bA2dkZycnJKF++vJErJiKi0sYeFjIZ+ZNsT548ie7du+OLL77Q7MvNzYVarUZaWhqcnZ2NWCURERkDAwuZlMTERMycOROnTp1C9+7dMWnSJAAo8IZmIiIyLwwsZHLyQ8vZs2fRtm1bhIWFGbskIiIyMj7plkyOSqXClClTUK1aNRw/fhyPHj0ydklERGRk7GEhk5WUlAQAcHFxMXIlRERkbAwsREREZPI4JEREREQmj4GFiIiITB4DCxEREZk8BhYiIiIyeQwsREREZPIYWIiIiMjkMbAQERGRyWNgITIzwcHB6N69u+Zz69atMWrUqFKv49ChQxAEAampqS89RhAEbNu2rcjnDA0NRf369fWq6/bt2xAEAefOndPrPERkWAwsRCYgODgYgiBAEARYWVmhatWqCA8Px7Nnz0r82lu2bMH06dOLdGxRQgYRUUng62+JTET79u2xatUqZGdn45dffsGwYcNQpkwZTJ48ucCxOTk5sLKyMsh1HR0dDXIeIqKSxB4WIhMhl8uhUqng4eGB//znP/D398fPP/8M4J9hnJkzZ8LNzQ3e3t4AgISEBPTq1Qv29vZwdHREt27dcPv2bc058/LyMGbMGNjb28PJyQkTJkzAi2/jeHFIKDs7GxMnToS7uzvkcjmqVq2KlStX4vbt22jTpg0AwMHBAYIgIDg4GACgVqsREREBLy8v2NjYoF69evjpp5+0rvPLL7+gevXqsLGxQZs2bbTqLKqJEyeievXqKFu2LCpXroyQkBDk5uYWOO7bb7+Fu7s7ypYti169eiEtLU1r//fffw8fHx9YW1ujRo0aWLp0qc61EFHpYmAhMlE2NjbIycnRfD5w4ADi4+Oxb98+7Ny5E7m5uQgICICdnR2OHDmCY8eOoVy5cmjfvr3me/PmzcPq1avxf//3fzh69ChSUlKwdevWV163b9+++O9//4vIyEjExcXh22+/Rbly5eDu7o7NmzcDAOLj4/HgwQMsWrQIABAREYGoqCgsX74cly9fxujRo/HJJ5/g8OHDAJ4Hqx49eqBLly44d+4cBg4ciEmTJun8M7Gzs8Pq1atx5coVLFq0CN999x0WLFigdcz169exceNG7NixA7t378bZs2cxdOhQzf5169Zh6tSpmDlzJuLi4jBr1iyEhIRgzZo1OtdDRKVIJCKjCwoKErt16yaKoiiq1Wpx3759olwuF8eNG6fZ7+LiImZnZ2u+s3btWtHb21tUq9WatuzsbNHGxkbcs2ePKIqi6OrqKs6ZM0ezPzc3V6xYsaLmWqIoiq1atRI///xzURRFMT4+XgQg7tu3r9A6f/vtNxGA+PjxY01bVlaWWLZsWfH48eNaxw4YMED86KOPRFEUxcmTJ4s1a9bU2j9x4sQC53oRAHHr1q0v3f/111+LjRo10nyeNm2aaGFhIf7555+atl9//VWUyWTigwcPRFEUxSpVqojr16/XOs/06dNFX19fURRF8datWyIA8ezZsy+9LhGVPs5hITIRO3fuRLly5ZCbmwu1Wo2PP/4YoaGhmv116tTRmrdy/vx5XL9+HXZ2dlrnycrKwo0bN5CWloYHDx6gadOmmn2WlpZo3LhxgWGhfOfOnYOFhQVatWpV5LqvX7+Op0+f4r333tNqz8nJQYMGDQAAcXFxWnUAgK+vb5Gvke/HH39EZGQkbty4gYyMDDx79gwKhULrmEqVKuGtt97Suo5arUZ8fDzs7Oxw48YNDBgwAIMGDdIc8+zZMyiVSp3rIaLSw8BCZCLatGmDZcuWwcrKCm5ubrC01P7H09bWVutzRkYGGjVqhHXr1hU4V4UKFYpVg42Njc7fycjIAADs2rVLKygAz+flGEpMTAwCAwMRFhaGgIAAKJVKbNiwAfPmzdO51u+++65AgLKwsDBYrURkeAwsRCbC1tYWVatWLfLxDRs2xI8//ghnZ+cCvQz5XF1dcfLkSbRs2RLA856E2NhYNGzYsNDj69SpA7VajcOHD8Pf37/A/vwenry8PE1bzZo1IZfLcffu3Zf2zPj4+GgmEOc7ceLE62/yX44fPw4PDw9MmTJF03bnzp0Cx929exf379+Hm5ub5joymQze3t5wcXGBm5sbbt68icDAQJ2uT0TGxUm3RBIVGBiI8uXLo1u3bjhy5Ahu3bqFQ4cOYeTIkfjzzz8BAJ9//jm++uorbNu2DX/88QeGDh36ymeoeHp6IigoCP3798e2bds059y4cSMAwMPDA4IgYOfOnfjrr7+QkZEBOzs7jBs3DqNHj8aaNWtw48YNnDlzBosXL9ZMZB0yZAiuXbuG8ePHIz4+HuvXr8fq1at1ut9q1arh7t272LBhA27cuIHIyMhCJxBbW1sjKCgI58+fx5EjRzBy5Ej06tULKpUKABAWFoaIiAhERkbi6tWruHjxIlatWoX58+frVA8RlS4GFiKJKlu2LKKjo1GpUiX06NEDPj4+GDBgALKysjQ9LmPHjsWnn36KoKAg+Pr6ws7ODu+///4rz7ts2TJ88MEHGDp0KGrUqIFBgwYhMzMTAPDWW28hLCwMkyZNgouLC4YPHw4AmD59OkJCQhAREQEfHx+0b98eu3btgpeXF4Dn80o2b96Mbdu2oV69eli+fDlmzZql0/127doVo0ePxvDhw1G/fn0cP34cISEhBY6rWrUqevTogY4dO6Jdu3aoW7eu1rLlgQMH4vvvv8eqVatQp04dtGrVCqtXr9bUSkSmSRBfNvuOiIiIyESwh4WIiIhMHgMLERERmTwGFiIiIjJ5DCxERERk8hhYiIiIyOQxsBAREZHJY2AhIiIik8fAQkRERCaPgYWIiIhMHgMLERERmTwGFiIiIjJ5/w90OZEM4tu7owAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the quantized model\n",
    "if train_with_int:\n",
    "    print('model name: ', model_name)\n",
    "    # Load the model into an interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path='./saved_models/'+model_name+'_pqat_FullInt_Rescaled.tflite')\n",
    "    X_test_qat = X_test.astype('int8')\n",
    "    y_test_qat = y_test.astype('int8')\n",
    "    assert X_test_qat.dtype == np.int8 and y_test_qat.dtype == np.int8\n",
    "else:\n",
    "    interpreter = tf.lite.Interpreter(model_path='./saved_models/'+model_name+'_pqat_FullInt_FPInput.tflite')\n",
    "    X_test_qat = X_test.astype('float32')\n",
    "    y_test_qat = y_test.astype('int8')\n",
    "    assert X_test_qat.dtype == np.float32 and y_test_qat.dtype == np.int8\n",
    "\n",
    "# Allocate memory for the model's input Tensor(s)\n",
    "interpreter.allocate_tensors()\n",
    "# Get the model input and output details\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(\"input: \", input_details)\n",
    "print(\"output: \", output_details)\n",
    "predictions = np.zeros(X_test.shape[0])\n",
    "for i, test_data in enumerate(X_test_qat):\n",
    "    test_data = np.expand_dims(test_data, axis=0)\n",
    "    #print(test_data.shape)\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    if i%100 == 0:\n",
    "        # print(\"Evaluated on %d images.\" % test_image_index)\n",
    "        print('Evaluated on ', i, '.')\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "gt = np.argmax(y_test_qat, axis=-1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(gt, predictions)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# accuracy\n",
    "accuracy = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "print('accuracy: ', accuracy)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "\n",
    "f1_score = 2 * cm[1][1] / (2 * cm[1][1] + cm[0][1] + cm[1][0])\n",
    "print('f1_score: ', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the size of the pruned model and the full-precision model\n",
    "pqat_model_path = './saved_models/'+model_name+'_pqat_FullInt_'+('Rescaled' if train_with_int else 'FPInput')+'.tflite'\n",
    "qat_model_path = './saved_models/'+model_name+'_qat_FullInt_'+('Rescaled' if train_with_int else 'FPInput')+'.tflite'\n",
    "full_prec_model_path = './saved_models/'+model_name +('_Rescaled' if train_with_int else '')+'.tflite'\n",
    "print('Size of the pruned QAT model: ', get_gzipped_model_size(pqat_model_path))\n",
    "print('Size of the QAT model: ', get_gzipped_model_size(qat_model_path))\n",
    "print('Size of the full-precision model: ', get_gzipped_model_size(full_prec_model_path))\n",
    "print(\"The achieved compression ratio is %.2fx\" % (get_gzipped_model_size(full_prec_model_path) / get_gzipped_model_size(pqat_model_path)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
